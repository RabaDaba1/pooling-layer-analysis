{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28","include_colab_link":true},"accelerator":"TPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/RabaDaba1/pooling-layer-analysis/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"zCdNv3NWaRIW"}},{"cell_type":"code","source":"import os\nimport math\nfrom pathlib import Path\n\n\n\nimport torch\n\nimport torch.nn as nn\n\nimport torch.optim as optim\n\nimport torch.nn.functional as F\n\n\n\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.tensorboard import SummaryWriter\n\n\n\nimport numpy as np","metadata":{"id":"HOXbLwPxaRIZ","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.773434Z","iopub.execute_input":"2024-11-28T11:59:47.773837Z","iopub.status.idle":"2024-11-28T11:59:47.779161Z","shell.execute_reply.started":"2024-11-28T11:59:47.773806Z","shell.execute_reply":"2024-11-28T11:59:47.778305Z"}},"outputs":[],"execution_count":72},{"cell_type":"markdown","source":"# Constants","metadata":{"id":"9SplINJkaRIZ"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adtuGj3DaRIa","outputId":"839cbb81-56ee-4d26-e5d2-479717e49cfa","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.780672Z","iopub.execute_input":"2024-11-28T11:59:47.780933Z","iopub.status.idle":"2024-11-28T11:59:47.792722Z","shell.execute_reply.started":"2024-11-28T11:59:47.780908Z","shell.execute_reply":"2024-11-28T11:59:47.791881Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"BATCH_SIZE = 64\n\nNUM_WORKERS = 0","metadata":{"id":"6oAkffJ3aRIa","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.793669Z","iopub.execute_input":"2024-11-28T11:59:47.793914Z","iopub.status.idle":"2024-11-28T11:59:47.801992Z","shell.execute_reply.started":"2024-11-28T11:59:47.793891Z","shell.execute_reply":"2024-11-28T11:59:47.801178Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"ROOT_DIR = Path('.')\n\nDATA_DIR = ROOT_DIR / 'data'\n\nREPORTS_DIR = ROOT_DIR / 'reports'\n\nMODELS_DIR = REPORTS_DIR / 'models'\n\nRESULTS_DIR = REPORTS_DIR / 'results'\n\nRUNS_DIR = REPORTS_DIR / 'runs'","metadata":{"id":"r9_L3gqvaRIc","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.803008Z","iopub.execute_input":"2024-11-28T11:59:47.803313Z","iopub.status.idle":"2024-11-28T11:59:47.811650Z","shell.execute_reply.started":"2024-11-28T11:59:47.803277Z","shell.execute_reply":"2024-11-28T11:59:47.810870Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"# Data loading","metadata":{"id":"ZkSe5roFaRId"}},{"cell_type":"code","source":"train_transform = transforms.Compose(\n\n    [transforms.ToTensor(),\n\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n\n     transforms.RandomHorizontalFlip(p=0.5),\n\n     transforms.RandomVerticalFlip(p=0.5)]\n\n)\n\nval_transform = transforms.Compose(\n\n    [transforms.ToTensor(),\n\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n\n     transforms.RandomHorizontalFlip(p=0.5),\n\n     transforms.RandomVerticalFlip(p=0.5)]\n\n)\n\ntest_transform = transforms.Compose(\n\n    [transforms.ToTensor(),\n\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n\n)","metadata":{"id":"fYnKNiFeaRId","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.813316Z","iopub.execute_input":"2024-11-28T11:59:47.813581Z","iopub.status.idle":"2024-11-28T11:59:47.822337Z","shell.execute_reply.started":"2024-11-28T11:59:47.813556Z","shell.execute_reply":"2024-11-28T11:59:47.821474Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"train_proportion = 0.9\n\nnum_train = 50000\n\n\n\nindices = list(range(num_train))\n\nsplit = int(np.floor(train_proportion * num_train))\n\nnp.random.shuffle(indices)\n\n\n\ntrain_idx, val_idx = indices[:split], indices[split:]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\n\nval_sampler = SubsetRandomSampler(val_idx)","metadata":{"id":"4EYWeP2SaRIe","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.823374Z","iopub.execute_input":"2024-11-28T11:59:47.823696Z","iopub.status.idle":"2024-11-28T11:59:47.839218Z","shell.execute_reply.started":"2024-11-28T11:59:47.823660Z","shell.execute_reply":"2024-11-28T11:59:47.838387Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"\n\ntrain_dataset = datasets.CIFAR10(root=DATA_DIR, train=True,\n\n                                 download=True, transform=train_transform)\n\n\n\nval_dataset = datasets.CIFAR10(root=DATA_DIR, train=True,\n\n                               download=True, transform=val_transform)\n\n\n\ntest_dataset = datasets.CIFAR10(root=DATA_DIR, train=False,\n\n                                download=True, transform=test_transform)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aAxDvk4aRIe","outputId":"3716a7ae-cf0f-4d19-d825-1ffdc4079c14","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.840315Z","iopub.execute_input":"2024-11-28T11:59:47.840905Z","iopub.status.idle":"2024-11-28T11:59:50.202886Z","shell.execute_reply.started":"2024-11-28T11:59:47.840867Z","shell.execute_reply":"2024-11-28T11:59:50.202151Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                          sampler=train_sampler, num_workers=NUM_WORKERS, pin_memory=True)\n\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                        sampler=val_sampler, num_workers=NUM_WORKERS, pin_memory=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                         num_workers=NUM_WORKERS, pin_memory=True)","metadata":{"id":"-mvema9saRIf","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.203936Z","iopub.execute_input":"2024-11-28T11:59:50.204449Z","iopub.status.idle":"2024-11-28T11:59:50.218542Z","shell.execute_reply.started":"2024-11-28T11:59:50.204413Z","shell.execute_reply":"2024-11-28T11:59:50.217615Z"}},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":"# Aggregating functions","metadata":{"id":"7Q1jegINaRIf"}},{"cell_type":"code","source":"def arithmetic_mean(X, dim, keepdim):\n\n    return torch.mean(X, dim, keepdim)","metadata":{"id":"zrryLKnoaRIg","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.219573Z","iopub.execute_input":"2024-11-28T11:59:50.219850Z","iopub.status.idle":"2024-11-28T11:59:50.231476Z","shell.execute_reply.started":"2024-11-28T11:59:50.219824Z","shell.execute_reply":"2024-11-28T11:59:50.230788Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def minimum(X, dim, keepdim):\n\n    return torch.min(X, dim, keepdim).values","metadata":{"id":"NWmJ9fZaaRIg","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.232609Z","iopub.execute_input":"2024-11-28T11:59:50.233026Z","iopub.status.idle":"2024-11-28T11:59:50.241577Z","shell.execute_reply.started":"2024-11-28T11:59:50.232988Z","shell.execute_reply":"2024-11-28T11:59:50.240778Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def product(X, dim, keepdim):\n\n    return torch.prod(X, dim=dim, keepdim=keepdim)","metadata":{"id":"ui3cx4RLaRIh","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.244047Z","iopub.execute_input":"2024-11-28T11:59:50.244282Z","iopub.status.idle":"2024-11-28T11:59:50.250950Z","shell.execute_reply.started":"2024-11-28T11:59:50.244258Z","shell.execute_reply":"2024-11-28T11:59:50.250121Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def t_norm_lukasiewicz(X, dim, keepdim):\n\n    sum_X = torch.sum(X, dim=dim, keepdim=keepdim) - 1\n\n    return torch.max(sum_X, torch.tensor(0, device=X.device))","metadata":{"id":"hXxMpfPSaRIi","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.251862Z","iopub.execute_input":"2024-11-28T11:59:50.252103Z","iopub.status.idle":"2024-11-28T11:59:50.263491Z","shell.execute_reply.started":"2024-11-28T11:59:50.252079Z","shell.execute_reply":"2024-11-28T11:59:50.262789Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"def t_norm_hamacher(tensor, dim, keepdim=False): \n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    # Indexar la útlima dimensión facilita la legibilidad del código (tendríamos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (hará las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-norma es asociativa, trataremos los elementos de 2 en 2. En cada iteración:\n            x = out_tensor\n            y = tensor[..., i]\n            diff_indices = torch.logical_or(x != 0, y != 0)\n            # if x == y == 0 -> 0 (we already have it)\n            # otherwise -> T(a, b) = (ab) / (a+b-ab)\n            out_tensor[diff_indices] = (\n                torch.mul(x[diff_indices], y[diff_indices]) / (x[diff_indices] + y[diff_indices] - torch.mul(x[diff_indices], y[diff_indices])))\n            \n    else:\n        raise Exception('Use dim=-1')\n    # If keepdims is True, expand the reduced dimension to size 1\n    if keepdim:\n        out_tensor = out_tensor.unsqueeze(dim)\n    \n    return out_tensor","metadata":{"id":"JpekXW3MaRIi","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.264497Z","iopub.execute_input":"2024-11-28T11:59:50.264764Z","iopub.status.idle":"2024-11-28T11:59:50.276439Z","shell.execute_reply.started":"2024-11-28T11:59:50.264716Z","shell.execute_reply":"2024-11-28T11:59:50.275763Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def maximum(X, dim, keepdim):\n    return torch.max(X, dim, keepdim).values","metadata":{"id":"OqRYbKGLaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.277424Z","iopub.execute_input":"2024-11-28T11:59:50.277732Z","iopub.status.idle":"2024-11-28T11:59:50.286768Z","shell.execute_reply.started":"2024-11-28T11:59:50.277707Z","shell.execute_reply":"2024-11-28T11:59:50.285869Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"def t_conorm_lukasiewicz(X, dim, keepdim):\n    sum_X = torch.sum(X, dim=dim, keepdim=keepdim)\n    return torch.min(sum_X, torch.tensor(1.0, device=X.device))","metadata":{"id":"l0nT5RUOaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.287990Z","iopub.execute_input":"2024-11-28T11:59:50.288337Z","iopub.status.idle":"2024-11-28T11:59:50.297489Z","shell.execute_reply.started":"2024-11-28T11:59:50.288299Z","shell.execute_reply":"2024-11-28T11:59:50.296777Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"def t_conorm_hamacher(tensor, dim = -1, keepdim = False):\n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    ones = tensor.new_ones(tensor_shape)\n    # Indexar la Ãºtlima dimensiÃ³n facilita la legibilidad del cÃ³digo (tendrÃ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-conorma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            diff_indices = torch.where(torch.abs(torch.mul(x, y)-1) > 1e-9) # Devuelve los Ã­ndices de los elementos para los cuÃ¡les x*y-1 > 0 (condiciÃ³n de la funciÃ³n por partes)\n            # Asignamos los valores en funciÃ³n de las condiciones\n            # if ab == 1 -> T(a, b) = 1\n            out_tensor = ones  # Por defecto, asumimos que todos los valores caen en el caso x*y-1=0\n            # otherwise -> T(a, b) = (2ab - a - b) / (ab - 1)\n            out_tensor[diff_indices] = (\n                2 * torch.mul(x[diff_indices], y[diff_indices]) - x[diff_indices] - y[diff_indices]) / (\n                torch.mul(x[diff_indices], y[diff_indices]) - 1)  # Corregimos los valores para los cuÃ¡les x*y-1>0 (los que corresponden a los Ã­ndices de diff_indices)\n    else:\n        # El cÃ³digo serÃ­a idÃ©ntico, sustituyendo tensor[..., 0] por torch.index_select(tensor, dim, tensor.new_tensor([0], dtype=torch.int)).squeeze(dim)\n        # torch.index_select(tensor, dim, tensor.new_tensor([0], dtype=torch.int)).squeeze(dim) indexa todos los elementos de la dimensiÃ³n dim\n        # NO HACE FALTA IMPLEMENTARLO\n        raise Exception('Utilizar la versiÃ³n con dim=-1')\n    if keepdim:\n        torch.unsqueeze(out_tensor, dim=dim)\n    return out_tensor","metadata":{"id":"-oWGPmCPaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.298355Z","iopub.execute_input":"2024-11-28T11:59:50.298583Z","iopub.status.idle":"2024-11-28T11:59:50.310238Z","shell.execute_reply.started":"2024-11-28T11:59:50.298561Z","shell.execute_reply":"2024-11-28T11:59:50.309471Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"def u_min_max(tensor, dim = -1, keepdim = False):\n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    ones = tensor.new_ones(tensor_shape)\n    # Indexar la Ãºtlima dimensiÃ³n facilita la legibilidad del cÃ³digo (tendrÃ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-conorma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            cond1 = torch.logical_or(x < 0, y > 0.5)\n            cond2 = torch.logical_or(x < 0, y > 0.5)\n            diff_indices = torch.logical_or(cond1, cond2)\n            # Asignamos los valores en funciÃ³n de las condiciones\n            # if a, b in [0,0'5]^2 -> U(a, b) = min(a,b)\n            #out_tensor = torch.min(x,y).values  \n            # otherwise -> U(a, b) = max(a,b)\n            #out_tensor[diff_indices] = (torch.max(x,y).values) \n            out_tensor = torch.where(diff_indices, torch.max(x, y), torch.min(x, y))\n    else:\n        raise Exception('Utilizar la versiÃ³n con dim=-1')\n    if keepdim:\n        torch.unsqueeze(out_tensor, dim=dim)\n    return out_tensor","metadata":{"id":"WV8eF-N_aRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.311070Z","iopub.execute_input":"2024-11-28T11:59:50.311298Z","iopub.status.idle":"2024-11-28T11:59:50.325444Z","shell.execute_reply.started":"2024-11-28T11:59:50.311275Z","shell.execute_reply":"2024-11-28T11:59:50.324793Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"def u_l_l(tensor, dim = -1, keepdim = False):\n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    ones = tensor.new_ones(tensor_shape)\n    # Indexar la Ãºtlima dimensiÃ³n facilita la legibilidad del cÃ³digo (tendrÃ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-conorma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            \n            # Condiciones\n            cond1 = torch.logical_and(x <= 0.5, y <= 0.5)  # Caso 1: (x, y) en [0, 0.5]^2\n            cond2 = torch.logical_and(x >= 0.5, y >= 0.5)  # Caso 2: (x, y) en [0.5, 1]^2\n            cond3 = ~(cond1 | cond2)  # Caso 3: En cualquier otro caso\n\n            # Caso 1: max(x + y - 1, 0)\n            if cond1.any():\n                out_tensor[cond1] = torch.maximum(\n                    x[cond1] + y[cond1] - 1, \n                    torch.tensor(0.0, device=tensor.device)\n                )\n\n            # Caso 2: min(x + y, 1)\n            if cond2.any():\n                out_tensor[cond2] = torch.minimum(\n                    x[cond2] + y[cond2], \n                    torch.tensor(1.0, device=tensor.device)\n                )\n\n            # Caso 3: max(x, y)\n            if cond3.any():\n                out_tensor[cond3] = torch.maximum(x[cond3], y[cond3])\n                \n    else:\n        raise Exception('Utilizar la versiÃ³n con dim=-1')\n    if keepdim:\n        torch.unsqueeze(out_tensor, dim=dim)\n    return out_tensor","metadata":{"id":"a4vs69DbaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.326468Z","iopub.execute_input":"2024-11-28T11:59:50.326803Z","iopub.status.idle":"2024-11-28T11:59:50.336233Z","shell.execute_reply.started":"2024-11-28T11:59:50.326764Z","shell.execute_reply":"2024-11-28T11:59:50.335379Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"class ChoquetLayer(nn.Module):\n\n    def __init__(self):\n        super(ChoquetLayer, self).__init__()\n        self.w = None\n\n    def forward(self, x, dim, keepdim):\n        input_size = x.size(-1)\n        batch_size = x.size(0)\n        if self.w is None or self.w.size(0) != batch_size:\n            self.w = nn.Parameter(torch.randn(input_size)).to(device)\n\n        x_sorted, indices = torch.sort(x, descending=True, dim=-1)  # (batch_size, input_size)\n        v_Ai = self.compute_v_Ai(indices)  # (batch_size, n+1)\n        v_delta = v_Ai[..., :-1] - v_Ai[..., 1:]  # (batch_size, input_size)\n        x = torch.sum(x_sorted * v_delta, dim=-1)  # (batch_size)\n\n        if keepdim:\n          x.unsqueeze(dim)\n\n        return x\n\n    def compute_v_Ai(self, indices):\n        w_sorted = self.w[indices]\n        v_Ai = torch.cumsum(w_sorted, dim=-1)\n        zeros = torch.zeros(*v_Ai.shape[:-1], 1).to(v_Ai.device)\n        v_Ai = torch.cat((zeros, v_Ai), dim=-1)\n\n        return v_Ai","metadata":{"id":"-qvp15RTaRIk","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.337276Z","iopub.execute_input":"2024-11-28T11:59:50.337522Z","iopub.status.idle":"2024-11-28T11:59:50.352426Z","shell.execute_reply.started":"2024-11-28T11:59:50.337498Z","shell.execute_reply":"2024-11-28T11:59:50.351655Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"# Layers","metadata":{"id":"Lj-tSUZoaRIk"}},{"cell_type":"code","source":"class AggPoolingLayer(nn.Module):\n    def __init__(self, function, kernel_size, stride, padding= [0,0,0,0], dim = -1, keepdim = False):\n        super().__init__()\n\n        # Una tupla de 2 elementos con los tamaños [𝑘1,𝑘2] de cada ventana a tratar\n        self.kernel_size = kernel_size\n        # Tupla de 2 elementos que indican el número de elementos (en filas y columnas) que\n        # deben saltarse tras reducir cada ventana, hasta encontrar la siguiente a tratar.\n        self.stride = stride\n\n        # Tupla de 4 elementos de la forma [𝑝𝑎𝑑_𝑙𝑒𝑓𝑡,𝑝𝑎𝑑_𝑟𝑖𝑔ℎ𝑡,𝑝𝑎𝑑_𝑢𝑝,𝑝𝑎𝑑_𝑑𝑜𝑤𝑛] que indica el\n        # número de nuevas filas o columnas a añadir a la entrada, previo a aplicar la agregación.\n        self.padding = padding\n\n        # Define function and characteristics\n        self.function = function\n        self.dim = dim\n        self.keepdim = keepdim\n\n    def forward(self, X):\n        # Normalize\n        maximum = torch.max(X)\n        minimum = torch.min(X)\n        X = (X-minimum)/(maximum-minimum)\n        # Añadir columnas/filas según padding\n        X_pad = F.pad(X, pad=self.padding, mode='constant', value=0)\n        # Vamos extrayendo las ventanas a agregar y colocándolas en filas\n        X_aux = X_pad.unfold(2, size=self.kernel_size[0], step=self.stride[0]).unfold(3, size=self.kernel_size[1], step=self.stride[1])\n        # Ponemos el formato correcto\n        X_aux = X_aux.reshape([X_aux.shape[0], X_aux.shape[1], X_aux.shape[2], X_aux.shape[3], X_aux.shape[4] * X_aux.shape[5]])\n        # Agg Func\n        Y_temp = self.function(X_aux, dim = self.dim, keepdim = self.keepdim)\n        # Denormalize\n        Y = minimum + (maximum-minimum) * Y_temp\n\n        return Y","metadata":{"id":"_1qzWROpaRIk","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.353724Z","iopub.execute_input":"2024-11-28T11:59:50.354497Z","iopub.status.idle":"2024-11-28T11:59:50.370159Z","shell.execute_reply.started":"2024-11-28T11:59:50.354455Z","shell.execute_reply":"2024-11-28T11:59:50.369282Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"class OWAPoolingLayer(nn.Module):\n\n\n\n    def __init__(self, kernel_size, stride, padding= [0,0,0,0], dim = -1, keepdim = False):\n\n        super().__init__()\n\n\n\n        # Una tupla de 2 elementos con los tamaños [𝑘1,𝑘2] de cada ventana a tratar\n\n        self.kernel_size = kernel_size\n\n\n\n        # Tupla de 2 elementos que indican el número de elementos (en filas y columnas) que\n\n        # deben saltarse tras reducir cada ventana, hasta encontrar la siguiente a tratar.\n\n        self.stride = stride\n\n\n\n        # Tupla de 4 elementos de la forma [𝑝𝑎𝑑_𝑙𝑒𝑓𝑡,𝑝𝑎𝑑_𝑟𝑖𝑔ℎ𝑡,𝑝𝑎𝑑_𝑢𝑝,𝑝𝑎𝑑_𝑑𝑜𝑤𝑛] que indica el\n\n        # número de nuevas filas o columnas a añadir a la entrada, previo a aplicar la agregación.\n\n        self.padding = padding\n\n\n\n        # Define characteristics\n\n        self.dim = dim\n\n        self.keepdim = keepdim\n\n\n\n        # Weights\n\n        self.weight = nn.Parameter(torch.ones(1, self.kernel_size[0] * self.kernel_size[1]))\n\n\n\n\n\n    def funcionOWA(self, X):\n\n\n\n        tensor_ordered = torch.sort(X, descending = True)\n\n        weight_norm = torch.nn.functional.softmax(self.weight, dim = self.dim)\n\n        output = torch.sum(tensor_ordered[0] * weight_norm, dim = self.dim, keepdim = self.keepdim)\n\n\n\n        return output\n\n\n\n    def forward(self, X):\n\n\n\n        # Normalize\n\n        maximum = torch.max(X)\n\n        minimum = torch.min(X)\n\n        X = (X-minimum)/(maximum-minimum)\n\n\n\n        # Añadir columnas/filas según padding\n\n        X_pad = F.pad(X, pad=self.padding, mode='constant', value=0)\n\n\n\n        # Vamos extrayendo las ventanas a agregar y colocándolas en filas\n\n        X_aux = X_pad.unfold(2, size=self.kernel_size[0], step=self.stride[0]).unfold(3, size=self.kernel_size[1], step=self.stride[1])\n\n\n\n        # Ponemos el formato correcto\n\n        X_aux = X_aux.reshape([X_aux.shape[0], X_aux.shape[1], X_aux.shape[2], X_aux.shape[3], X_aux.shape[4] * X_aux.shape[5]])\n\n\n\n        # Agg Func\n\n        Y_temp = self.funcionOWA(X_aux)\n\n\n\n        # Denormalize\n\n        Y = minimum + (maximum-minimum) * Y_temp\n\n\n\n        return Y","metadata":{"id":"gkaPYqtVaRIl","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.371325Z","iopub.execute_input":"2024-11-28T11:59:50.371932Z","iopub.status.idle":"2024-11-28T11:59:50.388240Z","shell.execute_reply.started":"2024-11-28T11:59:50.371893Z","shell.execute_reply":"2024-11-28T11:59:50.387285Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"# Model","metadata":{"id":"AHAyDZeoaRIl"}},{"cell_type":"code","source":"class LeNetModel(nn.Module):\n    def __init__(self, function, conv_filters=[64, 64], linear_sizes=[384, 192], num_classes=10):\n        super(LeNetModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, conv_filters[0], [3,3], [1,1])\n        self.pool1 = AggPoolingLayer(ChoquetLayer(), [2,2], [2,2])\n        self.conv2 = nn.Conv2d(conv_filters[0], conv_filters[1], [3,3], [1,1])\n        self.pool2 = AggPoolingLayer(ChoquetLayer(), [2,2], [2,2])\n        self.fc1 = nn.Linear(conv_filters[1]*6*6, linear_sizes[0])\n        self.fc2 = nn.Linear(linear_sizes[0], linear_sizes[1])\n        self.fc3 = nn.Linear(linear_sizes[1], num_classes)\n\n    def forward(self, x: torch.Tensor):\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = x.flatten(start_dim=1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n\n        return x","metadata":{"id":"qelKXZzRaRIm","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.389311Z","iopub.execute_input":"2024-11-28T11:59:50.389595Z","iopub.status.idle":"2024-11-28T11:59:50.400795Z","shell.execute_reply.started":"2024-11-28T11:59:50.389568Z","shell.execute_reply":"2024-11-28T11:59:50.399958Z"}},"outputs":[],"execution_count":93},{"cell_type":"markdown","source":"# Training","metadata":{"id":"Ng8cvSRRaRIn"}},{"cell_type":"code","source":"writer = SummaryWriter(log_dir=RUNS_DIR)","metadata":{"id":"ZHy7wYvxaRIn","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.401862Z","iopub.execute_input":"2024-11-28T11:59:50.402177Z","iopub.status.idle":"2024-11-28T11:59:50.417203Z","shell.execute_reply.started":"2024-11-28T11:59:50.402140Z","shell.execute_reply":"2024-11-28T11:59:50.416601Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, val_loader=None, num_epochs=20, device=device):\n    train_acc = []\n    train_loss = []\n\n    # if val_loader is not None:\n    val_acc = []\n    val_loss = []\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        count_evaluated = 0\n        count_correct = 0\n\n        for batch_idx, data in enumerate(train_loader, 0):\n\n            model.train()\n\n            inputs, labels = data[0].to(device), data[1].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n\n            loss = criterion(outputs, labels)\n\n            loss.backward()\n\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            count_evaluated += inputs.shape[0]\n\n            count_correct += torch.sum(labels == torch.max(outputs, dim=1)[1])\n\n\n\n        print('Training: [%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / (batch_idx+1)))\n\n\n\n        train_loss.append(running_loss / (batch_idx+1))\n\n        train_acc.append(float(count_correct) / count_evaluated)\n\n\n\n        if val_loader is not None:\n\n            running_loss_val = 0.0\n\n            count_evaluated = 0\n\n            count_correct = 0\n\n            model.eval()\n\n\n\n            with torch.no_grad():\n\n                for val_batch_idx, data_val in enumerate(val_loader, 0):\n\n                    inputs_val, labels_val = data_val[0].to(device), data_val[1].to(device)\n\n                    outputs_val = model(inputs_val)\n\n                    loss = criterion(outputs_val, labels_val)\n\n                    running_loss_val += loss.item()\n\n                    count_evaluated += inputs_val.shape[0]\n\n                    count_correct += torch.sum(labels_val == torch.max(outputs_val, dim=1)[1])\n\n\n\n                val_loss.append(running_loss_val / (val_batch_idx + 1))\n\n                acc_val = float(count_correct) / count_evaluated\n\n\n\n                print('Validation: epoch %d - acc: %.3f' %\n\n                            (epoch + 1, acc_val))\n\n                val_acc.append(acc_val)\n\n\n\n        # Tensorboard\n\n        writer.add_scalar('Loss/Validation', val_loss[-1], global_step=epoch)\n\n        writer.add_scalar('Accuracy/Validation', val_acc[-1], global_step=epoch)\n\n        writer.add_scalar('Loss/Train', train_loss[-1], global_step=epoch)\n\n        writer.add_scalar('Accuracy/Train', train_acc[-1], global_step=epoch)\n\n        for name, param in model.named_parameters():\n\n            writer.add_histogram(f\"Parameters/{name}\", param, epoch)\n\n            if param.grad is not None:\n\n                writer.add_histogram(f\"Gradients/{name}\", param.grad, epoch)\n\n\n\n    return model","metadata":{"id":"YLkCtKCxaRIn","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.418204Z","iopub.execute_input":"2024-11-28T11:59:50.418471Z","iopub.status.idle":"2024-11-28T11:59:50.429664Z","shell.execute_reply.started":"2024-11-28T11:59:50.418442Z","shell.execute_reply":"2024-11-28T11:59:50.428795Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"# Testing","metadata":{"id":"ky_kj4JWaRIo"}},{"cell_type":"code","source":"def test(model, test_loader, criterion, device='cuda'):\n\n    with torch.no_grad():\n\n        number_samples = 0\n\n        number_correct = 0\n\n        running_loss_test = 0.0\n\n        for test_batch_idx, data_test in enumerate(test_loader, 0):\n\n            inputs_test, labels_test = data_test[0].to(device), data_test[1].long().to(device)\n\n            outputs_test = model(inputs_test)\n\n            loss = criterion(outputs_test, labels_test)\n\n            running_loss_test += loss.cpu().numpy()\n\n\n\n            _, outputs_class = torch.max(outputs_test, dim=1)\n\n            number_correct += torch.sum(outputs_class == labels_test).cpu().numpy()\n\n            number_samples += len(labels_test)\n\n\n\n        acc_test = number_correct / number_samples\n\n\n\n        print('Test - Accuracy: %.3f' % acc_test)\n\n        print('Test - CrossEntropy: %.3f' % (running_loss_test / (test_batch_idx+1)))","metadata":{"id":"5AZ1mU9XaRIo","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.430664Z","iopub.execute_input":"2024-11-28T11:59:50.430930Z","iopub.status.idle":"2024-11-28T11:59:50.444273Z","shell.execute_reply.started":"2024-11-28T11:59:50.430896Z","shell.execute_reply":"2024-11-28T11:59:50.443524Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"model = LeNetModel(ChoquetLayer).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrained_model = train(model, train_loader, criterion, optimizer, val_loader=val_loader)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"PhCwjeFcam4k","outputId":"40c878e2-f1f7-4fcd-8ad2-2103080c94ad","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.447094Z","iopub.execute_input":"2024-11-28T11:59:50.447340Z"}},"outputs":[{"name":"stdout","text":"Training: [1,   704] loss: 2.290\nValidation: epoch 1 - acc: 0.191\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"iiQKSuMdcozt","trusted":true},"outputs":[],"execution_count":null}]}