{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28","include_colab_link":true},"accelerator":"TPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/RabaDaba1/pooling-layer-analysis/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"zCdNv3NWaRIW"}},{"cell_type":"code","source":"import os\nimport math\nfrom pathlib import Path\n\n\n\nimport torch\n\nimport torch.nn as nn\n\nimport torch.optim as optim\n\nimport torch.nn.functional as F\n\n\n\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.tensorboard import SummaryWriter\n\n\n\nimport numpy as np","metadata":{"id":"HOXbLwPxaRIZ","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.773434Z","iopub.execute_input":"2024-11-28T11:59:47.773837Z","iopub.status.idle":"2024-11-28T11:59:47.779161Z","shell.execute_reply.started":"2024-11-28T11:59:47.773806Z","shell.execute_reply":"2024-11-28T11:59:47.778305Z"}},"outputs":[],"execution_count":72},{"cell_type":"markdown","source":"# Constants","metadata":{"id":"9SplINJkaRIZ"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adtuGj3DaRIa","outputId":"839cbb81-56ee-4d26-e5d2-479717e49cfa","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.780672Z","iopub.execute_input":"2024-11-28T11:59:47.780933Z","iopub.status.idle":"2024-11-28T11:59:47.792722Z","shell.execute_reply.started":"2024-11-28T11:59:47.780908Z","shell.execute_reply":"2024-11-28T11:59:47.791881Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"BATCH_SIZE = 64\n\nNUM_WORKERS = 0","metadata":{"id":"6oAkffJ3aRIa","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.793669Z","iopub.execute_input":"2024-11-28T11:59:47.793914Z","iopub.status.idle":"2024-11-28T11:59:47.801992Z","shell.execute_reply.started":"2024-11-28T11:59:47.793891Z","shell.execute_reply":"2024-11-28T11:59:47.801178Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"ROOT_DIR = Path('.')\n\nDATA_DIR = ROOT_DIR / 'data'\n\nREPORTS_DIR = ROOT_DIR / 'reports'\n\nMODELS_DIR = REPORTS_DIR / 'models'\n\nRESULTS_DIR = REPORTS_DIR / 'results'\n\nRUNS_DIR = REPORTS_DIR / 'runs'","metadata":{"id":"r9_L3gqvaRIc","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.803008Z","iopub.execute_input":"2024-11-28T11:59:47.803313Z","iopub.status.idle":"2024-11-28T11:59:47.811650Z","shell.execute_reply.started":"2024-11-28T11:59:47.803277Z","shell.execute_reply":"2024-11-28T11:59:47.810870Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"# Data loading","metadata":{"id":"ZkSe5roFaRId"}},{"cell_type":"code","source":"train_transform = transforms.Compose(\n\n    [transforms.ToTensor(),\n\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n\n     transforms.RandomHorizontalFlip(p=0.5),\n\n     transforms.RandomVerticalFlip(p=0.5)]\n\n)\n\nval_transform = transforms.Compose(\n\n    [transforms.ToTensor(),\n\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n\n     transforms.RandomHorizontalFlip(p=0.5),\n\n     transforms.RandomVerticalFlip(p=0.5)]\n\n)\n\ntest_transform = transforms.Compose(\n\n    [transforms.ToTensor(),\n\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n\n)","metadata":{"id":"fYnKNiFeaRId","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.813316Z","iopub.execute_input":"2024-11-28T11:59:47.813581Z","iopub.status.idle":"2024-11-28T11:59:47.822337Z","shell.execute_reply.started":"2024-11-28T11:59:47.813556Z","shell.execute_reply":"2024-11-28T11:59:47.821474Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"train_proportion = 0.9\n\nnum_train = 50000\n\n\n\nindices = list(range(num_train))\n\nsplit = int(np.floor(train_proportion * num_train))\n\nnp.random.shuffle(indices)\n\n\n\ntrain_idx, val_idx = indices[:split], indices[split:]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\n\nval_sampler = SubsetRandomSampler(val_idx)","metadata":{"id":"4EYWeP2SaRIe","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.823374Z","iopub.execute_input":"2024-11-28T11:59:47.823696Z","iopub.status.idle":"2024-11-28T11:59:47.839218Z","shell.execute_reply.started":"2024-11-28T11:59:47.823660Z","shell.execute_reply":"2024-11-28T11:59:47.838387Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"\n\ntrain_dataset = datasets.CIFAR10(root=DATA_DIR, train=True,\n\n                                 download=True, transform=train_transform)\n\n\n\nval_dataset = datasets.CIFAR10(root=DATA_DIR, train=True,\n\n                               download=True, transform=val_transform)\n\n\n\ntest_dataset = datasets.CIFAR10(root=DATA_DIR, train=False,\n\n                                download=True, transform=test_transform)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aAxDvk4aRIe","outputId":"3716a7ae-cf0f-4d19-d825-1ffdc4079c14","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:47.840315Z","iopub.execute_input":"2024-11-28T11:59:47.840905Z","iopub.status.idle":"2024-11-28T11:59:50.202886Z","shell.execute_reply.started":"2024-11-28T11:59:47.840867Z","shell.execute_reply":"2024-11-28T11:59:50.202151Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                          sampler=train_sampler, num_workers=NUM_WORKERS, pin_memory=True)\n\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                        sampler=val_sampler, num_workers=NUM_WORKERS, pin_memory=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                         num_workers=NUM_WORKERS, pin_memory=True)","metadata":{"id":"-mvema9saRIf","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.203936Z","iopub.execute_input":"2024-11-28T11:59:50.204449Z","iopub.status.idle":"2024-11-28T11:59:50.218542Z","shell.execute_reply.started":"2024-11-28T11:59:50.204413Z","shell.execute_reply":"2024-11-28T11:59:50.217615Z"}},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":"# Aggregating functions","metadata":{"id":"7Q1jegINaRIf"}},{"cell_type":"code","source":"def arithmetic_mean(X, dim, keepdim):\n\n    return torch.mean(X, dim, keepdim)","metadata":{"id":"zrryLKnoaRIg","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.219573Z","iopub.execute_input":"2024-11-28T11:59:50.219850Z","iopub.status.idle":"2024-11-28T11:59:50.231476Z","shell.execute_reply.started":"2024-11-28T11:59:50.219824Z","shell.execute_reply":"2024-11-28T11:59:50.230788Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def minimum(X, dim, keepdim):\n\n    return torch.min(X, dim, keepdim).values","metadata":{"id":"NWmJ9fZaaRIg","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.232609Z","iopub.execute_input":"2024-11-28T11:59:50.233026Z","iopub.status.idle":"2024-11-28T11:59:50.241577Z","shell.execute_reply.started":"2024-11-28T11:59:50.232988Z","shell.execute_reply":"2024-11-28T11:59:50.240778Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def product(X, dim, keepdim):\n\n    return torch.prod(X, dim=dim, keepdim=keepdim)","metadata":{"id":"ui3cx4RLaRIh","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.244047Z","iopub.execute_input":"2024-11-28T11:59:50.244282Z","iopub.status.idle":"2024-11-28T11:59:50.250950Z","shell.execute_reply.started":"2024-11-28T11:59:50.244258Z","shell.execute_reply":"2024-11-28T11:59:50.250121Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def t_norm_lukasiewicz(X, dim, keepdim):\n\n    sum_X = torch.sum(X, dim=dim, keepdim=keepdim) - 1\n\n    return torch.max(sum_X, torch.tensor(0, device=X.device))","metadata":{"id":"hXxMpfPSaRIi","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.251862Z","iopub.execute_input":"2024-11-28T11:59:50.252103Z","iopub.status.idle":"2024-11-28T11:59:50.263491Z","shell.execute_reply.started":"2024-11-28T11:59:50.252079Z","shell.execute_reply":"2024-11-28T11:59:50.262789Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"def t_norm_hamacher(tensor, dim, keepdim=False): \n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    # Indexar la Ãºtlima dimensiÃ³n facilita la legibilidad del cÃ³digo (tendrÃ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-norma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            diff_indices = torch.logical_or(x != 0, y != 0)\n            # if x == y == 0 -> 0 (we already have it)\n            # otherwise -> T(a, b) = (ab) / (a+b-ab)\n            out_tensor[diff_indices] = (\n                torch.mul(x[diff_indices], y[diff_indices]) / (x[diff_indices] + y[diff_indices] - torch.mul(x[diff_indices], y[diff_indices])))\n            \n    else:\n        raise Exception('Use dim=-1')\n    # If keepdims is True, expand the reduced dimension to size 1\n    if keepdim:\n        out_tensor = out_tensor.unsqueeze(dim)\n    \n    return out_tensor","metadata":{"id":"JpekXW3MaRIi","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.264497Z","iopub.execute_input":"2024-11-28T11:59:50.264764Z","iopub.status.idle":"2024-11-28T11:59:50.276439Z","shell.execute_reply.started":"2024-11-28T11:59:50.264716Z","shell.execute_reply":"2024-11-28T11:59:50.275763Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def maximum(X, dim, keepdim):\n    return torch.max(X, dim, keepdim).values","metadata":{"id":"OqRYbKGLaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.277424Z","iopub.execute_input":"2024-11-28T11:59:50.277732Z","iopub.status.idle":"2024-11-28T11:59:50.286768Z","shell.execute_reply.started":"2024-11-28T11:59:50.277707Z","shell.execute_reply":"2024-11-28T11:59:50.285869Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"def t_conorm_lukasiewicz(X, dim, keepdim):\n    sum_X = torch.sum(X, dim=dim, keepdim=keepdim)\n    return torch.min(sum_X, torch.tensor(1.0, device=X.device))","metadata":{"id":"l0nT5RUOaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.287990Z","iopub.execute_input":"2024-11-28T11:59:50.288337Z","iopub.status.idle":"2024-11-28T11:59:50.297489Z","shell.execute_reply.started":"2024-11-28T11:59:50.288299Z","shell.execute_reply":"2024-11-28T11:59:50.296777Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"def t_conorm_hamacher(tensor, dim = -1, keepdim = False):\n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    ones = tensor.new_ones(tensor_shape)\n    # Indexar la ÃƒÂºtlima dimensiÃƒÂ³n facilita la legibilidad del cÃƒÂ³digo (tendrÃƒÂ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃƒÂ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-conorma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃƒÂ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            diff_indices = torch.where(torch.abs(torch.mul(x, y)-1) > 1e-9) # Devuelve los ÃƒÂ­ndices de los elementos para los cuÃƒÂ¡les x*y-1 > 0 (condiciÃƒÂ³n de la funciÃƒÂ³n por partes)\n            # Asignamos los valores en funciÃƒÂ³n de las condiciones\n            # if ab == 1 -> T(a, b) = 1\n            out_tensor = ones  # Por defecto, asumimos que todos los valores caen en el caso x*y-1=0\n            # otherwise -> T(a, b) = (2ab - a - b) / (ab - 1)\n            out_tensor[diff_indices] = (\n                2 * torch.mul(x[diff_indices], y[diff_indices]) - x[diff_indices] - y[diff_indices]) / (\n                torch.mul(x[diff_indices], y[diff_indices]) - 1)  # Corregimos los valores para los cuÃƒÂ¡les x*y-1>0 (los que corresponden a los ÃƒÂ­ndices de diff_indices)\n    else:\n        # El cÃƒÂ³digo serÃƒÂ­a idÃƒÂ©ntico, sustituyendo tensor[..., 0] por torch.index_select(tensor, dim, tensor.new_tensor([0], dtype=torch.int)).squeeze(dim)\n        # torch.index_select(tensor, dim, tensor.new_tensor([0], dtype=torch.int)).squeeze(dim) indexa todos los elementos de la dimensiÃƒÂ³n dim\n        # NO HACE FALTA IMPLEMENTARLO\n        raise Exception('Utilizar la versiÃƒÂ³n con dim=-1')\n    if keepdim:\n        torch.unsqueeze(out_tensor, dim=dim)\n    return out_tensor","metadata":{"id":"-oWGPmCPaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.298355Z","iopub.execute_input":"2024-11-28T11:59:50.298583Z","iopub.status.idle":"2024-11-28T11:59:50.310238Z","shell.execute_reply.started":"2024-11-28T11:59:50.298561Z","shell.execute_reply":"2024-11-28T11:59:50.309471Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"def u_min_max(tensor, dim = -1, keepdim = False):\n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    ones = tensor.new_ones(tensor_shape)\n    # Indexar la ÃƒÂºtlima dimensiÃƒÂ³n facilita la legibilidad del cÃƒÂ³digo (tendrÃƒÂ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃƒÂ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-conorma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃƒÂ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            cond1 = torch.logical_or(x < 0, y > 0.5)\n            cond2 = torch.logical_or(x < 0, y > 0.5)\n            diff_indices = torch.logical_or(cond1, cond2)\n            # Asignamos los valores en funciÃƒÂ³n de las condiciones\n            # if a, b in [0,0'5]^2 -> U(a, b) = min(a,b)\n            #out_tensor = torch.min(x,y).values  \n            # otherwise -> U(a, b) = max(a,b)\n            #out_tensor[diff_indices] = (torch.max(x,y).values) \n            out_tensor = torch.where(diff_indices, torch.max(x, y), torch.min(x, y))\n    else:\n        raise Exception('Utilizar la versiÃƒÂ³n con dim=-1')\n    if keepdim:\n        torch.unsqueeze(out_tensor, dim=dim)\n    return out_tensor","metadata":{"id":"WV8eF-N_aRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.311070Z","iopub.execute_input":"2024-11-28T11:59:50.311298Z","iopub.status.idle":"2024-11-28T11:59:50.325444Z","shell.execute_reply.started":"2024-11-28T11:59:50.311275Z","shell.execute_reply":"2024-11-28T11:59:50.324793Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"def u_l_l(tensor, dim = -1, keepdim = False):\n    tensor_shape = list(tensor.shape)\n    tensor_shape.pop(dim)\n    out_tensor = tensor.new_zeros(tensor_shape)\n    ones = tensor.new_ones(tensor_shape)\n    # Indexar la ÃƒÂºtlima dimensiÃƒÂ³n facilita la legibilidad del cÃƒÂ³digo (tendrÃƒÂ­amos que usar torch.index_select en caso contrario)\n    if (dim == -1) or (dim == len(tensor.shape)-1):\n        out_tensor = tensor[..., 0] # Tensor auxiliar donde acumularemos la salida (harÃƒÂ¡ las veces de x)\n        for i in range(1, tensor.shape[dim]):  # La t-conorma es asociativa: Trataremos los elementos de 2 en 2\n            # Dado que la t-conorma es asociativa, trataremos los elementos de 2 en 2. En cada iteraciÃƒÂ³n:\n            x = out_tensor\n            y = tensor[..., i]\n            \n            # Condiciones\n            cond1 = torch.logical_and(x <= 0.5, y <= 0.5)  # Caso 1: (x, y) en [0, 0.5]^2\n            cond2 = torch.logical_and(x >= 0.5, y >= 0.5)  # Caso 2: (x, y) en [0.5, 1]^2\n            cond3 = ~(cond1 | cond2)  # Caso 3: En cualquier otro caso\n\n            # Caso 1: max(x + y - 1, 0)\n            if cond1.any():\n                out_tensor[cond1] = torch.maximum(\n                    x[cond1] + y[cond1] - 1, \n                    torch.tensor(0.0, device=tensor.device)\n                )\n\n            # Caso 2: min(x + y, 1)\n            if cond2.any():\n                out_tensor[cond2] = torch.minimum(\n                    x[cond2] + y[cond2], \n                    torch.tensor(1.0, device=tensor.device)\n                )\n\n            # Caso 3: max(x, y)\n            if cond3.any():\n                out_tensor[cond3] = torch.maximum(x[cond3], y[cond3])\n                \n    else:\n        raise Exception('Utilizar la versiÃƒÂ³n con dim=-1')\n    if keepdim:\n        torch.unsqueeze(out_tensor, dim=dim)\n    return out_tensor","metadata":{"id":"a4vs69DbaRIj","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.326468Z","iopub.execute_input":"2024-11-28T11:59:50.326803Z","iopub.status.idle":"2024-11-28T11:59:50.336233Z","shell.execute_reply.started":"2024-11-28T11:59:50.326764Z","shell.execute_reply":"2024-11-28T11:59:50.335379Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"class ChoquetLayer(nn.Module):\n\n    def __init__(self):\n        super(ChoquetLayer, self).__init__()\n        self.w = None\n\n    def forward(self, x, dim, keepdim):\n        input_size = x.size(-1)\n        batch_size = x.size(0)\n        if self.w is None or self.w.size(0) != batch_size:\n            self.w = nn.Parameter(torch.randn(input_size)).to(device)\n\n        x_sorted, indices = torch.sort(x, descending=True, dim=-1)  # (batch_size, input_size)\n        v_Ai = self.compute_v_Ai(indices)  # (batch_size, n+1)\n        v_delta = v_Ai[..., :-1] - v_Ai[..., 1:]  # (batch_size, input_size)\n        x = torch.sum(x_sorted * v_delta, dim=-1)  # (batch_size)\n\n        if keepdim:\n          x.unsqueeze(dim)\n\n        return x\n\n    def compute_v_Ai(self, indices):\n        w_sorted = self.w[indices]\n        v_Ai = torch.cumsum(w_sorted, dim=-1)\n        zeros = torch.zeros(*v_Ai.shape[:-1], 1).to(v_Ai.device)\n        v_Ai = torch.cat((zeros, v_Ai), dim=-1)\n\n        return v_Ai","metadata":{"id":"-qvp15RTaRIk","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.337276Z","iopub.execute_input":"2024-11-28T11:59:50.337522Z","iopub.status.idle":"2024-11-28T11:59:50.352426Z","shell.execute_reply.started":"2024-11-28T11:59:50.337498Z","shell.execute_reply":"2024-11-28T11:59:50.351655Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"# Layers","metadata":{"id":"Lj-tSUZoaRIk"}},{"cell_type":"code","source":"class AggPoolingLayer(nn.Module):\n    def __init__(self, function, kernel_size, stride, padding= [0,0,0,0], dim = -1, keepdim = False):\n        super().__init__()\n\n        # Una tupla de 2 elementos con los tamaÃ±os [ğ‘˜1,ğ‘˜2] de cada ventana a tratar\n        self.kernel_size = kernel_size\n        # Tupla de 2 elementos que indican el nÃºmero de elementos (en filas y columnas) que\n        # deben saltarse tras reducir cada ventana, hasta encontrar la siguiente a tratar.\n        self.stride = stride\n\n        # Tupla de 4 elementos de la forma [ğ‘ğ‘ğ‘‘_ğ‘™ğ‘’ğ‘“ğ‘¡,ğ‘ğ‘ğ‘‘_ğ‘Ÿğ‘–ğ‘”â„ğ‘¡,ğ‘ğ‘ğ‘‘_ğ‘¢ğ‘,ğ‘ğ‘ğ‘‘_ğ‘‘ğ‘œğ‘¤ğ‘›] que indica el\n        # nÃºmero de nuevas filas o columnas a aÃ±adir a la entrada, previo a aplicar la agregaciÃ³n.\n        self.padding = padding\n\n        # Define function and characteristics\n        self.function = function\n        self.dim = dim\n        self.keepdim = keepdim\n\n    def forward(self, X):\n        # Normalize\n        maximum = torch.max(X)\n        minimum = torch.min(X)\n        X = (X-minimum)/(maximum-minimum)\n        # AÃ±adir columnas/filas segÃºn padding\n        X_pad = F.pad(X, pad=self.padding, mode='constant', value=0)\n        # Vamos extrayendo las ventanas a agregar y colocÃ¡ndolas en filas\n        X_aux = X_pad.unfold(2, size=self.kernel_size[0], step=self.stride[0]).unfold(3, size=self.kernel_size[1], step=self.stride[1])\n        # Ponemos el formato correcto\n        X_aux = X_aux.reshape([X_aux.shape[0], X_aux.shape[1], X_aux.shape[2], X_aux.shape[3], X_aux.shape[4] * X_aux.shape[5]])\n        # Agg Func\n        Y_temp = self.function(X_aux, dim = self.dim, keepdim = self.keepdim)\n        # Denormalize\n        Y = minimum + (maximum-minimum) * Y_temp\n\n        return Y","metadata":{"id":"_1qzWROpaRIk","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.353724Z","iopub.execute_input":"2024-11-28T11:59:50.354497Z","iopub.status.idle":"2024-11-28T11:59:50.370159Z","shell.execute_reply.started":"2024-11-28T11:59:50.354455Z","shell.execute_reply":"2024-11-28T11:59:50.369282Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"class OWAPoolingLayer(nn.Module):\n\n\n\n    def __init__(self, kernel_size, stride, padding= [0,0,0,0], dim = -1, keepdim = False):\n\n        super().__init__()\n\n\n\n        # Una tupla de 2 elementos con los tamaÃ±os [ğ‘˜1,ğ‘˜2] de cada ventana a tratar\n\n        self.kernel_size = kernel_size\n\n\n\n        # Tupla de 2 elementos que indican el nÃºmero de elementos (en filas y columnas) que\n\n        # deben saltarse tras reducir cada ventana, hasta encontrar la siguiente a tratar.\n\n        self.stride = stride\n\n\n\n        # Tupla de 4 elementos de la forma [ğ‘ğ‘ğ‘‘_ğ‘™ğ‘’ğ‘“ğ‘¡,ğ‘ğ‘ğ‘‘_ğ‘Ÿğ‘–ğ‘”â„ğ‘¡,ğ‘ğ‘ğ‘‘_ğ‘¢ğ‘,ğ‘ğ‘ğ‘‘_ğ‘‘ğ‘œğ‘¤ğ‘›] que indica el\n\n        # nÃºmero de nuevas filas o columnas a aÃ±adir a la entrada, previo a aplicar la agregaciÃ³n.\n\n        self.padding = padding\n\n\n\n        # Define characteristics\n\n        self.dim = dim\n\n        self.keepdim = keepdim\n\n\n\n        # Weights\n\n        self.weight = nn.Parameter(torch.ones(1, self.kernel_size[0] * self.kernel_size[1]))\n\n\n\n\n\n    def funcionOWA(self, X):\n\n\n\n        tensor_ordered = torch.sort(X, descending = True)\n\n        weight_norm = torch.nn.functional.softmax(self.weight, dim = self.dim)\n\n        output = torch.sum(tensor_ordered[0] * weight_norm, dim = self.dim, keepdim = self.keepdim)\n\n\n\n        return output\n\n\n\n    def forward(self, X):\n\n\n\n        # Normalize\n\n        maximum = torch.max(X)\n\n        minimum = torch.min(X)\n\n        X = (X-minimum)/(maximum-minimum)\n\n\n\n        # AÃ±adir columnas/filas segÃºn padding\n\n        X_pad = F.pad(X, pad=self.padding, mode='constant', value=0)\n\n\n\n        # Vamos extrayendo las ventanas a agregar y colocÃ¡ndolas en filas\n\n        X_aux = X_pad.unfold(2, size=self.kernel_size[0], step=self.stride[0]).unfold(3, size=self.kernel_size[1], step=self.stride[1])\n\n\n\n        # Ponemos el formato correcto\n\n        X_aux = X_aux.reshape([X_aux.shape[0], X_aux.shape[1], X_aux.shape[2], X_aux.shape[3], X_aux.shape[4] * X_aux.shape[5]])\n\n\n\n        # Agg Func\n\n        Y_temp = self.funcionOWA(X_aux)\n\n\n\n        # Denormalize\n\n        Y = minimum + (maximum-minimum) * Y_temp\n\n\n\n        return Y","metadata":{"id":"gkaPYqtVaRIl","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.371325Z","iopub.execute_input":"2024-11-28T11:59:50.371932Z","iopub.status.idle":"2024-11-28T11:59:50.388240Z","shell.execute_reply.started":"2024-11-28T11:59:50.371893Z","shell.execute_reply":"2024-11-28T11:59:50.387285Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"# Model","metadata":{"id":"AHAyDZeoaRIl"}},{"cell_type":"code","source":"class LeNetModel(nn.Module):\n    def __init__(self, function, conv_filters=[64, 64], linear_sizes=[384, 192], num_classes=10):\n        super(LeNetModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, conv_filters[0], [3,3], [1,1])\n        self.pool1 = AggPoolingLayer(ChoquetLayer(), [2,2], [2,2])\n        self.conv2 = nn.Conv2d(conv_filters[0], conv_filters[1], [3,3], [1,1])\n        self.pool2 = AggPoolingLayer(ChoquetLayer(), [2,2], [2,2])\n        self.fc1 = nn.Linear(conv_filters[1]*6*6, linear_sizes[0])\n        self.fc2 = nn.Linear(linear_sizes[0], linear_sizes[1])\n        self.fc3 = nn.Linear(linear_sizes[1], num_classes)\n\n    def forward(self, x: torch.Tensor):\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = x.flatten(start_dim=1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n\n        return x","metadata":{"id":"qelKXZzRaRIm","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.389311Z","iopub.execute_input":"2024-11-28T11:59:50.389595Z","iopub.status.idle":"2024-11-28T11:59:50.400795Z","shell.execute_reply.started":"2024-11-28T11:59:50.389568Z","shell.execute_reply":"2024-11-28T11:59:50.399958Z"}},"outputs":[],"execution_count":93},{"cell_type":"markdown","source":"# Training","metadata":{"id":"Ng8cvSRRaRIn"}},{"cell_type":"code","source":"writer = SummaryWriter(log_dir=RUNS_DIR)","metadata":{"id":"ZHy7wYvxaRIn","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.401862Z","iopub.execute_input":"2024-11-28T11:59:50.402177Z","iopub.status.idle":"2024-11-28T11:59:50.417203Z","shell.execute_reply.started":"2024-11-28T11:59:50.402140Z","shell.execute_reply":"2024-11-28T11:59:50.416601Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, val_loader=None, num_epochs=20, device=device):\n    train_acc = []\n    train_loss = []\n\n    # if val_loader is not None:\n    val_acc = []\n    val_loss = []\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        count_evaluated = 0\n        count_correct = 0\n\n        for batch_idx, data in enumerate(train_loader, 0):\n\n            model.train()\n\n            inputs, labels = data[0].to(device), data[1].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n\n            loss = criterion(outputs, labels)\n\n            loss.backward()\n\n            optimizer.step()\n\n            running_loss += loss.item()\n\n            count_evaluated += inputs.shape[0]\n\n            count_correct += torch.sum(labels == torch.max(outputs, dim=1)[1])\n\n\n\n        print('Training: [%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / (batch_idx+1)))\n\n\n\n        train_loss.append(running_loss / (batch_idx+1))\n\n        train_acc.append(float(count_correct) / count_evaluated)\n\n\n\n        if val_loader is not None:\n\n            running_loss_val = 0.0\n\n            count_evaluated = 0\n\n            count_correct = 0\n\n            model.eval()\n\n\n\n            with torch.no_grad():\n\n                for val_batch_idx, data_val in enumerate(val_loader, 0):\n\n                    inputs_val, labels_val = data_val[0].to(device), data_val[1].to(device)\n\n                    outputs_val = model(inputs_val)\n\n                    loss = criterion(outputs_val, labels_val)\n\n                    running_loss_val += loss.item()\n\n                    count_evaluated += inputs_val.shape[0]\n\n                    count_correct += torch.sum(labels_val == torch.max(outputs_val, dim=1)[1])\n\n\n\n                val_loss.append(running_loss_val / (val_batch_idx + 1))\n\n                acc_val = float(count_correct) / count_evaluated\n\n\n\n                print('Validation: epoch %d - acc: %.3f' %\n\n                            (epoch + 1, acc_val))\n\n                val_acc.append(acc_val)\n\n\n\n        # Tensorboard\n\n        writer.add_scalar('Loss/Validation', val_loss[-1], global_step=epoch)\n\n        writer.add_scalar('Accuracy/Validation', val_acc[-1], global_step=epoch)\n\n        writer.add_scalar('Loss/Train', train_loss[-1], global_step=epoch)\n\n        writer.add_scalar('Accuracy/Train', train_acc[-1], global_step=epoch)\n\n        for name, param in model.named_parameters():\n\n            writer.add_histogram(f\"Parameters/{name}\", param, epoch)\n\n            if param.grad is not None:\n\n                writer.add_histogram(f\"Gradients/{name}\", param.grad, epoch)\n\n\n\n    return model","metadata":{"id":"YLkCtKCxaRIn","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.418204Z","iopub.execute_input":"2024-11-28T11:59:50.418471Z","iopub.status.idle":"2024-11-28T11:59:50.429664Z","shell.execute_reply.started":"2024-11-28T11:59:50.418442Z","shell.execute_reply":"2024-11-28T11:59:50.428795Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"# Testing","metadata":{"id":"ky_kj4JWaRIo"}},{"cell_type":"code","source":"def test(model, test_loader, criterion, device='cuda'):\n\n    with torch.no_grad():\n\n        number_samples = 0\n\n        number_correct = 0\n\n        running_loss_test = 0.0\n\n        for test_batch_idx, data_test in enumerate(test_loader, 0):\n\n            inputs_test, labels_test = data_test[0].to(device), data_test[1].long().to(device)\n\n            outputs_test = model(inputs_test)\n\n            loss = criterion(outputs_test, labels_test)\n\n            running_loss_test += loss.cpu().numpy()\n\n\n\n            _, outputs_class = torch.max(outputs_test, dim=1)\n\n            number_correct += torch.sum(outputs_class == labels_test).cpu().numpy()\n\n            number_samples += len(labels_test)\n\n\n\n        acc_test = number_correct / number_samples\n\n\n\n        print('Test - Accuracy: %.3f' % acc_test)\n\n        print('Test - CrossEntropy: %.3f' % (running_loss_test / (test_batch_idx+1)))","metadata":{"id":"5AZ1mU9XaRIo","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.430664Z","iopub.execute_input":"2024-11-28T11:59:50.430930Z","iopub.status.idle":"2024-11-28T11:59:50.444273Z","shell.execute_reply.started":"2024-11-28T11:59:50.430896Z","shell.execute_reply":"2024-11-28T11:59:50.443524Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"model = LeNetModel(ChoquetLayer).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrained_model = train(model, train_loader, criterion, optimizer, val_loader=val_loader)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"PhCwjeFcam4k","outputId":"40c878e2-f1f7-4fcd-8ad2-2103080c94ad","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T11:59:50.447094Z","iopub.execute_input":"2024-11-28T11:59:50.447340Z"}},"outputs":[{"name":"stdout","text":"Training: [1,   704] loss: 2.290\nValidation: epoch 1 - acc: 0.191\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"iiQKSuMdcozt","trusted":true},"outputs":[],"execution_count":null}]}