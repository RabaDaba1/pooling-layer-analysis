{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we are going to implement different aggregating functions to create differente versions of pooling layers. Afterwards, the analysis of the results derived from different models will be performed, as well as the identification of different problems that will have appeared in the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Modifications of Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries that will be needed shall be imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # FFFFF\n",
    "\n",
    "# Data loading\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Auxiliary functions\n",
    "from torch.utils.tensorboard import SummaryWriter  # Used for Tensorboard logging\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor, ceil\n",
    "import datetime\n",
    "\n",
    "# Math\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we are going to establish a working hierarchy to have everything correctly organised:\n",
    "\n",
    "    ├── data               <- Directory for storing datasets\n",
    "    └── reports            <- Outputs produced by the model\n",
    "        ├── models         <- Trained and serialized models\n",
    "        ├── results        <- Results obtained after training, testing on the test set\n",
    "        └── runs           <- Logs generated during training, interpretable by tensorboard (tensorboard --logdir [namedir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, we establish the following paths that shall be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proofs Folder Path: 2024_10_31__13_0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PATH_ROOT = os.path.join('.')\n",
    "# Path for data:\n",
    "PATH_DATA = os.path.join(PATH_ROOT, 'data')\n",
    "# Path for models:\n",
    "PATH_MODELS = os.path.join(PATH_ROOT, 'reports', 'models')\n",
    "# Path for results:\n",
    "PATH_RESULTS = os.path.join(PATH_ROOT, 'reports', 'results')\n",
    "# Path for runnings:\n",
    "PATH_RUNS = os.path.join(PATH_ROOT, 'reports', 'runs')\n",
    "\n",
    "# For each session we create a new folder from the datetime of its execution. \n",
    "date = datetime.datetime.now()\n",
    "test_name = str(date.year) + '_' + str(date.month) + '_' +  str(date.day) + '__' + str(date.hour) + '_' + str(date.minute)\n",
    "print('Proofs Folder Path: {}'.format(test_name))\n",
    "models_folder = os.path.join(PATH_MODELS, test_name)\n",
    "try:\n",
    "    os.mkdir(models_folder)\n",
    "except:\n",
    "    print(f'Folder {models_folder} already existed.')\n",
    "results_folder = os.path.join(PATH_RESULTS, test_name)\n",
    "try:\n",
    "    os.mkdir(results_folder)\n",
    "except:\n",
    "    print(f'Folder {results_folder} already existed.')\n",
    "runs_folder = os.path.join(PATH_RUNS, test_name)\n",
    "try:\n",
    "    os.mkdir(runs_folder)\n",
    "except:\n",
    "    print(f'Folder {runs_folder} already existed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the existence of a GPU to accelerate the calculations is checked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existence of a GPU is proofed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data: Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the class lab, the data that will be used must be loaded. The very same dataset will be considered, and the same preprocessing will be applied before being sent to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data: Datasets and Dataloaders\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was also done in the class lab, the data loading is performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling method for train/val split\n",
    "train_proportion = 0.9  \n",
    "num_train = 50000  \n",
    "\n",
    "# Generate list with random indexes to choose the examples of each split\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(train_proportion * num_train))\n",
    "np.random.shuffle(indices)  # Random rearrange of indices\n",
    "\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "# Generate torch.utils.data.SubsetRandomSampler to get the examples randomly from the given indexes. \n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = datasets.CIFAR10(root=PATH_DATA, train=True, \n",
    "                                 download=True, transform=train_transform)\n",
    "\n",
    "val_dataset = datasets.CIFAR10(root=PATH_DATA, train=True, \n",
    "                               download=True, transform=val_transform)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=PATH_DATA, train=False,\n",
    "                                download=True, transform=test_transform)\n",
    "\n",
    "# DataLoader definition:\n",
    "# Dataloaders take care of loading data in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                          sampler=train_sampler, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                        sampler=val_sampler, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once batches of examples can be correctly loaded to the training pipeline, it is possible now to proceed with the definition of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the class lab, the LeNet-5 Model (basic architecture of CNN) will be considered. This architecture consists of: \n",
    "* Convolution Layers: With several filters; each of them produces a map of characteristics. \n",
    "* Pooling Layers: Reduces the dimensionality of the input due to an aggregating function. This part is the one that shall be modified by changing the aggregating function. \n",
    "* Lineal Layers: Related to a layer in a Neuronal Network. \n",
    "\n",
    "![Arquitectura LeNet-5](figures/LeNet-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Functions Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, several aggregating functions will be firstly mathematically explained and secondly programmed so that they could be used in the PoolingLayer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.0000, 0.3429],\n",
      "        [0.4739, 0.5834, 0.4028],\n",
      "        [0.6874, 0.5122, 0.6949]])\n",
      "tensor([0.4606, 0.4898, 0.6436], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "p = torch.randn([3,3], dtype=torch.float)\n",
    "#print(p)\n",
    "maximum = torch.max(p)\n",
    "minimum = torch.min(p)\n",
    "#print(maximum,minimum)\n",
    "p2 = (p-minimum)/(maximum-minimum)\n",
    "print(p2)\n",
    "#p3 = minimum + (maximum-minimum) * p2\n",
    "#print(p3)\n",
    "print(OWA(p2, -1, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arithmetic_mean(X, dim, keepdim):\n",
    "    return torch.mean(X, dim, keepdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OWA with Learnable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OWA(X, dim, keepdim):\n",
    "    \n",
    "    weight = nn.Parameter(torch.empty(1, X.shape[dim]))\n",
    "            \n",
    "    stdv = 1. / math.sqrt(weight.size(1))\n",
    "    weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    tensor_ordered = torch.sort(X, descending = True)\n",
    "    weight_norm = torch.nn.functional.softmax(weight, dim = dim)\n",
    "    output = torch.sum(tensor_ordered[0] * weight_norm, dim = dim, keepdim = keepdim)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OWALayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features)))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        # Inicializamos los valores de self.weight y self.bias\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Calculamos el producto matricial entre input y el vector de pesos pero estilo OWA:\n",
    "        # f(x) = x_1 * w_1 + ... + x_n * w_n\n",
    "        tensor_orden = torch.sort(input, descending = True)\n",
    "        weight_norm = torch.nn.functional.softmax(self.weight)\n",
    "        output = torch.matmul(tensor_orden[0], weight_norm.t())\n",
    "        if self.bias is not None:\n",
    "            # f(x) = x_1 * w_1 + ... + x_n * w_n + bias\n",
    "            output += self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggPoolingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size, stride, padding= [0,0,0,0], function, dim = -1, keepdim = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Una tupla de 2 elementos con los tamaños [𝑘1,𝑘2] de cada ventana a tratar\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Tupla de 2 elementos que indican el número de elementos (en filas y columnas) que \n",
    "        # deben saltarse tras reducir cada ventana, hasta encontrar la siguiente a tratar.\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Tupla de 4 elementos de la forma [𝑝𝑎𝑑_𝑙𝑒𝑓𝑡,𝑝𝑎𝑑_𝑟𝑖𝑔ℎ𝑡,𝑝𝑎𝑑_𝑢𝑝,𝑝𝑎𝑑_𝑑𝑜𝑤𝑛] que indica el \n",
    "        # número de nuevas filas o columnas a añadir a la entrada, previo a aplicar la agregación.\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Define function and characteristics\n",
    "        self.function = function\n",
    "        self.dim = dim\n",
    "        self.keepdim = keepdim\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # Normalize\n",
    "        maximum = torch.max(X)\n",
    "        minimum = torch.min(X)\n",
    "        X = (X-minimum)/(maximum-minimum)\n",
    "        \n",
    "        # Añadir columnas/filas según padding\n",
    "        X_pad = F.pad(X, pad=self.padding, mode='constant', value=0)\n",
    "        \n",
    "        # Vamos extrayendo las ventanas a agregar y colocándolas en filas\n",
    "        X_aux = X_pad.unfold(2, size=self.kernel_size[0], step=self.stride[0]).unfold(3, size=self.kernel_size[1], step=self.stride[1])\n",
    "        \n",
    "        # Ponemos el formato correcto\n",
    "        X_aux = X_aux.reshape([X_aux.shape[0], X_aux.shape[1], X_aux.shape[2], X_aux.shape[3], X_aux.shape[4] * X_aux.shape[5]]) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Agg Func\n",
    "        Y_temp = self.function(X_aux, dim = self.dim, keepdim = self.keepdim)\n",
    "        \n",
    "        # Denormalize \n",
    "        Y = minimum + (maximum-minimum) * Y_temp\n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Ejercicio 2**: </span> : Implementa el módulo LeNetModel que deberá recrear la arquitectura LeNet-5. Los parámetros de entrada del modelo serán: \n",
    "\n",
    "* conv_filters: Una lista con el número de filtros a aprender en cada capa de convolución. Por defecto [64, 64].\n",
    "* linear_sizes: Una lista con el número de neuronas de salida de cada capa lineal oculta del clasificador. Por defecto [384, 192].\n",
    "* num_clases: Entero que indica el número de clases a predecir en nuestro problema. Por defecto 10.\n",
    "\n",
    "La arquitectura de la red consta de:\n",
    "\n",
    "* Convolución con `conv_filters[0]` filtros de tamaño [2, 2] y stride [1, 1].\n",
    "* Pooling con *kernel size* [2, 2] y stride [2, 2].\n",
    "* Convolución con `conv_filters[1]` filtros de tamaño [2, 2] y stride [1, 1].\n",
    "* Pooling con *kernel size* [2, 2] y stride [2, 2].\n",
    "* Capa oculta lineal con `conv_filters[1] * 8 * 8` neuronas de entrada y `linear_sizes[0]` neuronas de salida.\n",
    "* Capa oculta lineal con `linear_sizes[0]` neuronas de entrada y `linear_sizes[1]` neuronas de salida.\n",
    "* Capa de salida lineal con `linear_sizes[1]` neuronas de entrada y `num_classes` neuronas de salida.\n",
    "\n",
    "El modelo deberá emplear la función ReLU como función de activación. Además, antes de la primera capa oculta lineal, se deberá convertir la salida $X$ de la capa anterior de tamaño `[batch_size, conv_filters[1], 8, 8]` en un tensor de tamaño `[batch_size, conv_filters[1] * 8, 8]` apto para servir de entrada a una capa *torch.nn.Linear*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetModel(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_filters=[64, 64], linear_sizes=[384, 192], num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_filters = conv_filters\n",
    "        \n",
    "        self.linear_sizes = linear_sizes\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Primera Convolución con conv_filters[0] filtros de tamaño [3, 3] y stride [1, 1] y padding [1, 1].    \n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels = 3, out_channels = self.conv_filters[0], kernel_size = [3, 3], stride = [1, 1], padding = [1, 1], device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Primer Pooling con kernel size [2, 2] y stride [2, 2]\n",
    "        self.pool_1 = PoolingLayer(kernel_size = [2, 2], stride = [2, 2])\n",
    "        \n",
    "        # Segundo Convolución con conv_filters[1] filtros de tamaño [3, 3] y stride [1, 1] y padding [1, 1].\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels = self.conv_filters[0], out_channels = self.conv_filters[1], kernel_size = [3, 3], stride = [1, 1], padding = [1, 1], device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Segundo Pooling con kernel size [2, 2] y stride [2, 2]\n",
    "        self.pool_2 = PoolingLayer(kernel_size = [2, 2], stride = [2, 2])\n",
    "        \n",
    "        # Primera Capa oculta lineal con conv_filters[1] * 8 * 8 neuronas de entrada y linear_sizes[0] neuronas de salida.\n",
    "        self.lin_1 = torch.nn.Linear(in_features = self.conv_filters[1] * 8 * 8, out_features = self.linear_sizes[0], bias=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Segunda Capa oculta lineal con linear_sizes[0] neuronas de entrada y linear_sizes[1] neuronas de salida.\n",
    "        self.lin_2 = torch.nn.Linear(in_features = self.linear_sizes[0], out_features = self.linear_sizes[1], bias=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Capa de salida lineal con linear_sizes[1] neuronas de entrada y num_classes neuronas de salida.\n",
    "        self.salida = torch.nn.Linear(in_features = self.linear_sizes[1], out_features = self.num_classes, bias=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # print(X.shape)\n",
    "        \n",
    "        # Ejecutamos primera Convolución \n",
    "        X_tras_conv_1 = self.conv_1(X)\n",
    "        #print(\"X_tras_conv_1.shape = \", X_tras_conv_1.shape)\n",
    "        \n",
    "        # Ejecutamos primer Pooling \n",
    "        X_tras_pool_1 = self.pool_1(X_tras_conv_1)\n",
    "        #print(\"X_tras_pool_1.shape = \", X_tras_pool_1.shape)\n",
    "        \n",
    "        # Ejecutamos segunda Convolución\n",
    "        X_tras_conv_2 = self.conv_2(X_tras_pool_1)\n",
    "        #print(\"X_tras_conv_2.shape = \", X_tras_conv_2.shape)\n",
    "        \n",
    "        # Ejecutamos Segundo Pooling\n",
    "        X_tras_pool_2 = self.pool_2(X_tras_conv_2)\n",
    "        #print(\"X_tras_pool_2.shape = \", X_tras_pool_2.shape)\n",
    "        \n",
    "        # Antes de la primera capa oculta lineal, se deberá convertir la salida 𝑋 de la capa anterior de tamaño \n",
    "        # [batch_size, conv_filters[1], 8, 8] en un tensor de tamaño [batch_size, conv_filters[1] * 8 * 8]\n",
    "        X_tras_rshp = X_tras_pool_2.reshape([X_tras_pool_2.shape[0], X_tras_pool_2.shape[1] * X_tras_pool_2.shape[2] * X_tras_pool_2.shape[3]])\n",
    "        #print(\"X_tras_rshp.shape = \",X_tras_rshp.shape)\n",
    "        \n",
    "        # Ejecutamos 1º Capa oculta lineal.\n",
    "        X_tras_lin_1 = self.lin_1(X_tras_rshp)\n",
    "        #print(\"X_tras_lin_1.shape = \", X_tras_lin_1.shape)\n",
    "        \n",
    "        # Le aplicamos ReLU\n",
    "        X_tras_relu_1 = F.relu(X_tras_lin_1)\n",
    "        #print(\"X_tras_relu_1.shape = \",X_tras_relu_1.shape)\n",
    "        \n",
    "        # Ejecutamos 2º capa oculta lineal \n",
    "        X_tras_lin_2 = self.lin_2(X_tras_relu_1)\n",
    "        #print(\"X_tras_lin_2.shape = \", X_tras_lin_2.shape)\n",
    "        \n",
    "        # Le aplicamos ReLU\n",
    "        X_tras_relu_2 = F.relu(X_tras_lin_2)\n",
    "        #print(\"X_tras_relu_2.shape = \", X_tras_relu_2.shape)\n",
    "        \n",
    "        # Ejecutamos Capa de salida lineal .\n",
    "        X_salida = self.salida(X_tras_relu_2)\n",
    "        #print(\"X_salida.shape = \", X_salida.shape)\n",
    "        \n",
    "        return X_salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de pasar a plantear el bucle de entrenamiento de nuestro nuevo modelo, vamos a presentar el modo de loggear información de nuestro modelo de modo que sea compatible con la herramienta [Tensorboard](https://www.tensorflow.org/tensorboard?hl=es-419). Aunque inicialmente se trataba de una herramienta desarrollada para trabajar con el framework Tensorflow (otra alternativa a PyTorch para Deep Learning), actualmente [es compatible con PyTorch](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "\n",
    "Tensorboard es una herramienta de visualización muy potente que permite, entre otras:\n",
    "\n",
    "* Registrar la evaluación de métricas de aprendizaje (como coste o tasa de acierto): Permite medir fácilmente el rendimiento del modelo en entrenamiento y compararlo con el de otras variantes del mismo u otros modelos.\n",
    "* Registrar distribuciones de valores (como las de los parámetros del modelo o sus gradientes): Facilita localizar problemas de entrenamiento del modelo, como \"gradientes desvanecientes\" o \"gradientes explosivos\".\n",
    "* Proyectar datos transformados a un espacio dimensional mejor (mediante algoritmos como PCA o T-SNE): Se puede utilizar sobre los vectores de características extraídos por el modelo a distintos niveles para comprender cómo diferencia el modelo entre las distintas clases. Veremos su uso en futuras prácticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comenzar ilustrando este proceso con un proceso muy simple, antes de incorporarlo a nuestra pipeline de entrenamiento.\n",
    "\n",
    "En PyTorch, la forma más fácil de registrar información para su posterior análisis con la herramienta, es a través del objeto *torch.utils.tensorboard.SummaryWriter*. Los pasos a seguir son:\n",
    "\n",
    "* Crear un *SummaryWriter* indicándole la ruta en la que almacenar los logs:\n",
    "\n",
    "    `writer = SummaryWriter(log_dir=runs_folder)`\n",
    "\n",
    "* Para registrar un valor escalar (por ejemplo el coste de nuestra función o la tasa de acierto), utilizaremos:\n",
    "\n",
    "    `writer.add_scalar(tag, scalar_value, global_step)`\n",
    "    * *tag* será un *string* con el que se identificará la variable a registrar.\n",
    "    * *scalar_value* será un *float* que contendrá el valor de esa variable en la iteración que estamos registrando.\n",
    "    * *global_step* será un *int* que indica la iteración que estamos registrando.\n",
    "\n",
    "Para ilustrar este proceso vamos a plantear el ejemplo que vimos en el Tutorial para optimizar los parámetros de la función:\n",
    "\n",
    "$$f(a) = w_3 * (w_1 * a) + w_4 * (w_2 * a)$$\n",
    "\n",
    "En esta ocasión, no obstante, vamos a utilizar algunos de los conceptos que ya conocemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l=tensor([32.], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-2.,  2., -4.,  3.], grad_fn=<ToCopyBackward0>); w.grad=tensor([-12.,   9.,  -6.,   6.], device='cuda:0')\n",
      "l=tensor([31.7033], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.9880,  1.9910, -3.9940,  2.9940], grad_fn=<ToCopyBackward0>); w.grad=tensor([-23.9820,  17.9820, -11.9640,  11.9730], device='cuda:0')\n",
      "l=tensor([31.1130], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.9640,  1.9730, -3.9820,  2.9820], grad_fn=<ToCopyBackward0>); w.grad=tensor([-35.9281,  26.9281, -17.8560,  17.8920], device='cuda:0')\n",
      "l=tensor([30.2351], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.9281,  1.9461, -3.9642,  2.9641], grad_fn=<ToCopyBackward0>); w.grad=tensor([-47.8206,  35.8204, -23.6403,  23.7303], device='cuda:0')\n",
      "l=tensor([29.0784], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.8803,  1.9103, -3.9405,  2.9404], grad_fn=<ToCopyBackward0>); w.grad=tensor([-59.6421,  44.6416, -29.2811,  29.4611], device='cuda:0')\n",
      "l=tensor([27.6547], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.8206,  1.8656, -3.9112,  2.9109], grad_fn=<ToCopyBackward0>); w.grad=tensor([-71.3759,  53.3744, -34.7429,  35.0579], device='cuda:0')\n",
      "l=tensor([25.9781], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.7492,  1.8122, -3.8765,  2.8759], grad_fn=<ToCopyBackward0>); w.grad=tensor([-83.0053,  62.0020, -39.9906,  40.4947], device='cuda:0')\n",
      "l=tensor([24.0652], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.6662,  1.7502, -3.8365,  2.8354], grad_fn=<ToCopyBackward0>); w.grad=tensor([-94.5148,  70.5081, -44.9893,  45.7454], device='cuda:0')\n",
      "l=tensor([21.9349], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.5717,  1.6797, -3.7915,  2.7896], grad_fn=<ToCopyBackward0>); w.grad=tensor([-105.8893,   78.8770,  -49.7045,   50.7846], device='cuda:0')\n",
      "l=tensor([19.6078], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.4658,  1.6008, -3.7418,  2.7388], grad_fn=<ToCopyBackward0>); w.grad=tensor([-117.1147,   87.0935,  -54.1020,   55.5871], device='cuda:0')\n",
      "l=tensor([17.1062], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.3487,  1.5138, -3.6877,  2.6832], grad_fn=<ToCopyBackward0>); w.grad=tensor([-128.1778,   95.1432,  -58.1481,   60.1284], device='cuda:0')\n",
      "l=tensor([14.4534], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.2205,  1.4186, -3.6295,  2.6231], grad_fn=<ToCopyBackward0>); w.grad=tensor([-139.0664,  103.0126,  -61.8097,   64.3842], device='cuda:0')\n",
      "l=tensor([11.6738], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.0815,  1.3156, -3.5677,  2.5587], grad_fn=<ToCopyBackward0>); w.grad=tensor([-149.7696,  110.6887,  -65.0541,   68.3310], device='cuda:0')\n",
      "l=tensor([8.7923], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.9317,  1.2049, -3.5027,  2.4904], grad_fn=<ToCopyBackward0>); w.grad=tensor([-160.2776,  118.1599,  -67.8492,   71.9457], device='cuda:0')\n",
      "l=tensor([5.8337], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7714,  1.0867, -3.4348,  2.4184], grad_fn=<ToCopyBackward0>); w.grad=tensor([-170.5820,  125.4153,  -70.1634,   75.2059], device='cuda:0')\n",
      "l=tensor([2.8226], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.6008,  0.9613, -3.3646,  2.3432], grad_fn=<ToCopyBackward0>); w.grad=tensor([-180.6760,  132.4450,  -71.9659,   78.0899], device='cuda:0')\n",
      "l=tensor([0.2171], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.4202,  0.8289, -3.2927,  2.2651], grad_fn=<ToCopyBackward0>); w.grad=tensor([-170.7979,  125.6495,  -70.7054,   75.6033], device='cuda:0')\n",
      "l=tensor([2.9705], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.2494,  0.7032, -3.2220,  2.1895], grad_fn=<ToCopyBackward0>); w.grad=tensor([-161.1320,  119.0809,  -69.9574,   73.4936], device='cuda:0')\n",
      "l=tensor([5.4575], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.0882,  0.5842, -3.1520,  2.1160], grad_fn=<ToCopyBackward0>); w.grad=tensor([-151.6760,  112.7328,  -69.6927,   71.7411], device='cuda:0')\n",
      "l=tensor([7.6956], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.0635,  0.4714, -3.0823,  2.0443], grad_fn=<ToCopyBackward0>); w.grad=tensor([-142.4291,  106.5999,  -69.8830,   70.3269], device='cuda:0')\n",
      "l=tensor([9.7002], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2059,  0.3648, -3.0124,  1.9740], grad_fn=<ToCopyBackward0>); w.grad=tensor([-133.3918,  100.6780,  -70.5007,   69.2324], device='cuda:0')\n",
      "l=tensor([11.4850], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.3393,  0.2641, -2.9419,  1.9047], grad_fn=<ToCopyBackward0>); w.grad=tensor([-124.5660,   94.9638,  -71.5185,   68.4400], device='cuda:0')\n",
      "l=tensor([13.0623], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.4638,  0.1692, -2.8704,  1.8363], grad_fn=<ToCopyBackward0>); w.grad=tensor([-115.9548,   89.4549,  -72.9100,   67.9325], device='cuda:0')\n",
      "l=tensor([14.4430], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.5798,  0.0797, -2.7975,  1.7684], grad_fn=<ToCopyBackward0>); w.grad=tensor([-107.5623,   84.1498,  -74.6494,   67.6933], device='cuda:0')\n",
      "l=tensor([15.6373], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.6874, -0.0044, -2.7228,  1.7007], grad_fn=<ToCopyBackward0>); w.grad=tensor([-99.3938,  79.0478, -76.7115,  67.7066], device='cuda:0')\n",
      "l=tensor([16.6545], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.7867, -0.0835, -2.6461,  1.6330], grad_fn=<ToCopyBackward0>); w.grad=tensor([-91.4555,  74.1489, -79.0717,  67.9570], device='cuda:0')\n",
      "l=tensor([17.5032], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.8782, -0.1576, -2.5670,  1.5650], grad_fn=<ToCopyBackward0>); w.grad=tensor([-83.7543,  69.4539, -81.7063,  68.4299], device='cuda:0')\n",
      "l=tensor([18.1919], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.9620, -0.2271, -2.4853,  1.4966], grad_fn=<ToCopyBackward0>); w.grad=tensor([-76.2983,  64.9642, -84.5922,  69.1112], device='cuda:0')\n",
      "l=tensor([18.7284], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.0383, -0.2920, -2.4007,  1.4275], grad_fn=<ToCopyBackward0>); w.grad=tensor([-69.0961,  60.6819, -87.7070,  69.9873], device='cuda:0')\n",
      "l=tensor([19.1205], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1073, -0.3527, -2.3130,  1.3575], grad_fn=<ToCopyBackward0>); w.grad=tensor([-62.1570,  56.6095, -91.0290,  71.0455], device='cuda:0')\n",
      "l=tensor([19.3757], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1695, -0.4093, -2.2220,  1.2864], grad_fn=<ToCopyBackward0>); w.grad=tensor([-55.4910,  52.7502, -94.5375,  72.2735], device='cuda:0')\n",
      "l=tensor([19.5015], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.2250, -0.4621, -2.1275,  1.2141], grad_fn=<ToCopyBackward0>); w.grad=tensor([-49.1086,  49.1078, -98.2125,  73.6598], device='cuda:0')\n",
      "l=tensor([19.5054], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.2741, -0.5112, -2.0292,  1.1405], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -43.0208,   45.6864, -102.0348,   75.1933], device='cuda:0')\n",
      "l=tensor([19.3948], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3171, -0.5569, -1.9272,  1.0653], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -37.2392,   42.4905, -105.9862,   76.8640], device='cuda:0')\n",
      "l=tensor([19.1771], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3544, -0.5994, -1.8212,  0.9884], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -31.7755,   39.5252, -110.0493,   78.6621], device='cuda:0')\n",
      "l=tensor([18.8595], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3861, -0.6389, -1.7112,  0.9098], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -26.6420,   36.7960, -114.2077,   80.5788], device='cuda:0')\n",
      "l=tensor([18.4493], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4128, -0.6757, -1.5970,  0.8292], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -21.8511,   34.3084, -118.4460,   82.6058], device='cuda:0')\n",
      "l=tensor([17.9535], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4346, -0.7100, -1.4785,  0.7466], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -17.4155,   32.0687, -122.7498,   84.7358], device='cuda:0')\n",
      "l=tensor([17.3792], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4520, -0.7421, -1.3558,  0.6618], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -13.3482,   30.0832, -127.1060,   86.9620], device='cuda:0')\n",
      "l=tensor([16.7330], device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=tensor([ 1.4654, -0.7721, -1.2287,  0.5749], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -9.6623,   28.3586, -131.5021,   89.2785], device='cuda:0')\n",
      "l=tensor([16.0212], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4750, -0.8005, -1.0972,  0.4856], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -6.3708,   26.9018, -135.9273,   91.6800], device='cuda:0')\n",
      "l=tensor([15.2497], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4814, -0.8274, -0.9612,  0.3939], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -3.4871,   25.7200, -140.3715,   94.1622], device='cuda:0')\n",
      "l=tensor([14.4238], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4849, -0.8531, -0.8209,  0.2998], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -1.0246,   24.8208, -144.8262,   96.7216], device='cuda:0')\n",
      "l=tensor([13.5483], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4859, -0.8779, -0.6760,  0.2030], grad_fn=<ToCopyBackward0>); w.grad=tensor([   1.0035,   24.2117, -149.2840,   99.3554], device='cuda:0')\n",
      "l=tensor([12.6271], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4849, -0.9022, -0.5267,  0.1037], grad_fn=<ToCopyBackward0>); w.grad=tensor([   2.5837,   23.9007, -153.7387,  102.0619], device='cuda:0')\n",
      "l=tensor([11.6632], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4823, -0.9261, -0.3730,  0.0016], grad_fn=<ToCopyBackward0>); w.grad=tensor([   3.7027,   23.8958, -158.1857,  104.8401], device='cuda:0')\n",
      "l=tensor([10.6587], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4786, -0.9500, -0.2148, -0.1032], grad_fn=<ToCopyBackward0>); w.grad=tensor([   4.3472,   24.2055, -162.6216,  107.6899], device='cuda:0')\n",
      "l=tensor([9.6144], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4743, -0.9742, -0.0522, -0.2109], grad_fn=<ToCopyBackward0>); w.grad=tensor([   4.5038,   24.8383, -167.0444,  110.6124], device='cuda:0')\n",
      "l=tensor([8.5300], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4698, -0.9990,  0.1148, -0.3215], grad_fn=<ToCopyBackward0>); w.grad=tensor([   4.1592,   25.8028, -171.4538,  113.6094], device='cuda:0')\n",
      "l=tensor([7.4034], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4656, -1.0248,  0.2863, -0.4351], grad_fn=<ToCopyBackward0>); w.grad=tensor([   3.3003,   27.1083, -175.8506,  116.6837], device='cuda:0')\n",
      "l=tensor([6.2312], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4623, -1.0519,  0.4622, -0.5518], grad_fn=<ToCopyBackward0>); w.grad=tensor([   1.9138,   28.7637, -180.2376,  119.8395], device='cuda:0')\n",
      "l=tensor([5.0080], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4604, -1.0807,  0.6424, -0.6717], grad_fn=<ToCopyBackward0>); w.grad=tensor([-1.3324e-02,  3.0779e+01, -1.8462e+02,  1.2308e+02], device='cuda:0')\n",
      "l=tensor([3.7268], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4604, -1.1114,  0.8270, -0.7947], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -2.4944,   33.1629, -189.0000,  126.4158], device='cuda:0')\n",
      "l=tensor([2.3780], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4629, -1.1446,  1.0160, -0.9212], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -5.5424,   35.9264, -193.3887,  129.8496], device='cuda:0')\n",
      "l=tensor([0.9500], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4684, -1.1805,  1.2094, -1.0510], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -9.1706,   39.0794, -197.7940,  133.3912], device='cuda:0')\n",
      "l=tensor([0.5713], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4776, -1.2196,  1.4072, -1.1844], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -4.9490,   35.5262, -193.3612,  129.7324], device='cuda:0')\n",
      "l=tensor([2.0669], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4826, -1.2551,  1.6005, -1.3141], grad_fn=<ToCopyBackward0>); w.grad=tensor([-1.4735e-01,  3.1584e+01, -1.8891e+02,  1.2597e+02], device='cuda:0')\n",
      "l=tensor([3.5187], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4827, -1.2867,  1.7895, -1.4401], grad_fn=<ToCopyBackward0>); w.grad=tensor([   5.2210,   27.2636, -184.4654,  122.1068], device='cuda:0')\n",
      "l=tensor([4.9074], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4775, -1.3140,  1.9739, -1.5622], grad_fn=<ToCopyBackward0>); w.grad=tensor([  11.1428,   22.5770, -180.0329,  118.1649], device='cuda:0')\n",
      "l=tensor([6.2130], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4663, -1.3366,  2.1540, -1.6804], grad_fn=<ToCopyBackward0>); w.grad=tensor([  17.6047,   17.5359, -175.6339,  114.1552], device='cuda:0')\n",
      "l=tensor([7.4146], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4487, -1.3541,  2.3296, -1.7945], grad_fn=<ToCopyBackward0>); w.grad=tensor([  24.5934,   12.1524, -171.2877,  110.0930], device='cuda:0')\n",
      "l=tensor([8.4912], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4241, -1.3662,  2.5009, -1.9046], grad_fn=<ToCopyBackward0>); w.grad=tensor([  32.0960,    6.4385, -167.0153,  105.9942], device='cuda:0')\n",
      "l=tensor([9.4211], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3920, -1.3727,  2.6679, -2.0106], grad_fn=<ToCopyBackward0>); w.grad=tensor([  40.0997,    0.4067, -162.8392,  101.8762], device='cuda:0')\n",
      "l=tensor([10.1827], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3519, -1.3731,  2.8307, -2.1125], grad_fn=<ToCopyBackward0>); w.grad=tensor([  48.5919,   -5.9307, -158.7834,   97.7570], device='cuda:0')\n",
      "l=tensor([10.7542], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3033, -1.3671,  2.9895, -2.2102], grad_fn=<ToCopyBackward0>); w.grad=tensor([  57.5604,  -12.5614, -154.8733,   93.6555], device='cuda:0')\n",
      "l=tensor([11.1140], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.2458, -1.3546,  3.1444, -2.3039], grad_fn=<ToCopyBackward0>); w.grad=tensor([  66.9935,  -19.4730, -151.1360,   89.5918], device='cuda:0')\n",
      "l=tensor([11.2408], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1788, -1.3351,  3.2955, -2.3935], grad_fn=<ToCopyBackward0>); w.grad=tensor([  76.8800,  -26.6534, -147.5996,   85.5864], device='cuda:0')\n",
      "l=tensor([11.1132], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1019, -1.3085,  3.4431, -2.4791], grad_fn=<ToCopyBackward0>); w.grad=tensor([  87.2093,  -34.0906, -144.2939,   81.6611], device='cuda:0')\n",
      "l=tensor([10.7102], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.0147, -1.2744,  3.5874, -2.5607], grad_fn=<ToCopyBackward0>); w.grad=tensor([  97.9715,  -41.7727, -141.2498,   77.8380], device='cuda:0')\n",
      "l=tensor([10.0112], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.9167, -1.2326,  3.7286, -2.6385], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 109.1574,  -49.6883, -138.4996,   74.1402], device='cuda:0')\n",
      "l=tensor([8.9954], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.8076, -1.1829,  3.8671, -2.7127], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 120.7588,  -57.8264, -136.0769,   70.5915], device='cuda:0')\n",
      "l=tensor([7.6425], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.6868, -1.1251,  4.0032, -2.7833], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 132.7684,  -66.1762, -134.0165,   67.2163], device='cuda:0')\n",
      "l=tensor([5.9317], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.5540, -1.0589,  4.1372, -2.8505], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 145.1801,  -74.7277, -132.3544,   64.0396], device='cuda:0')\n",
      "l=tensor([3.8421], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.4089, -0.9842,  4.2696, -2.9145], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 157.9888,  -83.4713, -131.1278,   61.0871], device='cuda:0')\n",
      "l=tensor([1.3524], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2509, -0.9007,  4.4007, -2.9756], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 171.1909,  -92.3981, -130.3752,   58.3850], device='cuda:0')\n",
      "l=tensor([1.5598], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.0797, -0.8083,  4.5311, -3.0340], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 157.5977,  -83.2961, -130.6142,   60.8099], device='cuda:0')\n",
      "l=tensor([4.3585], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.0779, -0.7250,  4.6617, -3.0948], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 143.6127,  -74.0117, -130.3804,   62.9849], device='cuda:0')\n",
      "l=tensor([7.0178], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.2215, -0.6510,  4.7920, -3.1578], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 129.2365,  -64.5384, -129.7159,   64.9378], device='cuda:0')\n",
      "l=tensor([9.5093], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.3508, -0.5864,  4.9218, -3.2227], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 114.4712,  -54.8702, -128.6635,   66.6972], device='cuda:0')\n",
      "l=tensor([11.8032], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.4652, -0.5316,  5.0504, -3.2894], grad_fn=<ToCopyBackward0>); w.grad=tensor([  99.3200,  -45.0020, -127.2678,   68.2919], device='cuda:0')\n",
      "l=tensor([13.8680], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.5646, -0.4866,  5.1777, -3.3577], grad_fn=<ToCopyBackward0>); w.grad=tensor([  83.7869,  -34.9289, -125.5741,   69.7516], device='cuda:0')\n",
      "l=tensor([15.6710], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.6483, -0.4516,  5.3033, -3.4274], grad_fn=<ToCopyBackward0>); w.grad=tensor([  67.8772,  -24.6466, -123.6291,   71.1066], device='cuda:0')\n",
      "l=tensor([17.1789], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7162, -0.4270,  5.4269, -3.4985], grad_fn=<ToCopyBackward0>); w.grad=tensor([  51.5966,  -14.1510, -121.4804,   72.3876], device='cuda:0')\n",
      "l=tensor([18.3576], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7678, -0.4128,  5.5484, -3.5709], grad_fn=<ToCopyBackward0>); w.grad=tensor([  34.9515,   -3.4382, -119.1770,   73.6261], device='cuda:0')\n",
      "l=tensor([19.1728], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8028, -0.4094,  5.6675, -3.6446], grad_fn=<ToCopyBackward0>); w.grad=tensor([  17.9489,    7.4955, -116.7687,   74.8543], device='cuda:0')\n",
      "l=tensor([19.5899], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8207, -0.4169,  5.7843, -3.7194], grad_fn=<ToCopyBackward0>); w.grad=tensor([   0.5961,   18.6537, -114.3065,   76.1050], device='cuda:0')\n",
      "l=tensor([19.5743], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8213, -0.4356,  5.8986, -3.7955], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -17.0997,   30.0402, -111.8426,   77.4117], device='cuda:0')\n",
      "l=tensor([19.0913], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8042, -0.4656,  6.0104, -3.8729], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -35.1309,   41.6590, -109.4300,   78.8085], device='cuda:0')\n",
      "l=tensor([18.1064], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7691, -0.5073,  6.1198, -3.9517], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -53.4905,   53.5141, -107.1227,   80.3303], device='cuda:0')\n",
      "l=tensor([16.5847], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7156, -0.5608,  6.2270, -4.0320], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -72.1714,   65.6103, -104.9760,   82.0126], device='cuda:0')\n",
      "l=tensor([14.4913], device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=tensor([-0.6434, -0.6264,  6.3319, -4.1141], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -91.1672,   77.9524, -103.0457,   83.8917], device='cuda:0')\n",
      "l=tensor([11.7909], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.5522, -0.7043,  6.4350, -4.1979], grad_fn=<ToCopyBackward0>); w.grad=tensor([-110.4721,   90.5463, -101.3890,   86.0047], device='cuda:0')\n",
      "l=tensor([8.4472], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.4418, -0.7949,  6.5364, -4.2839], grad_fn=<ToCopyBackward0>); w.grad=tensor([-130.0811,  103.3981, -100.0636,   88.3893], device='cuda:0')\n",
      "l=tensor([4.4230], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.3117, -0.8983,  6.6364, -4.3723], grad_fn=<ToCopyBackward0>); w.grad=tensor([-149.9904,  116.5151,  -99.1286,   91.0842], device='cuda:0')\n",
      "l=tensor([0.3207], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.1617, -1.0148,  6.7355, -4.4634], grad_fn=<ToCopyBackward0>); w.grad=tensor([-129.7838,  103.1248,  -99.6137,   88.0398], device='cuda:0')\n",
      "l=tensor([4.6098], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.0319, -1.1179,  6.8351, -4.5514], grad_fn=<ToCopyBackward0>); w.grad=tensor([-109.2784,   89.4705,  -99.7094,   84.6861], device='cuda:0')\n",
      "l=tensor([8.4021], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.0774, -1.2074,  6.9348, -4.6361], grad_fn=<ToCopyBackward0>); w.grad=tensor([-88.4738,  75.5621, -99.4773,  81.0639], device='cuda:0')\n",
      "l=tensor([11.6552], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.1658, -1.2829,  7.0343, -4.7172], grad_fn=<ToCopyBackward0>); w.grad=tensor([-67.3709,  61.4106, -98.9798,  77.2151], device='cuda:0')\n",
      "l=tensor([14.3266], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2332, -1.3444,  7.1333, -4.7944], grad_fn=<ToCopyBackward0>); w.grad=tensor([-45.9710,  47.0274, -98.2802,  73.1820], device='cuda:0')\n",
      "l=tensor([16.3745], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2792, -1.3914,  7.2316, -4.8676], grad_fn=<ToCopyBackward0>); w.grad=tensor([-24.2763,  32.4247, -97.4427,  69.0079], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard: Inicializamos nuestro objeto SummaryWriter con la ruta del test actual:\n",
    "writer = SummaryWriter(log_dir=runs_folder)\n",
    "\n",
    "# Inicializamos las variables a tratar:\n",
    "a = torch.tensor([3], dtype=torch.float).to(device)\n",
    "# w = torch.tensor([-.2, .2, -.4, .3], dtype=torch.float, device=device, requires_grad=True)\n",
    "w = nn.Parameter(torch.tensor([-2, 2, -4, 3], dtype=torch.float, device=device))\n",
    "# Nota: Creamos el tensor directamente en \"device\"\n",
    "# w = torch.tensor(...).to(device) no nos permitiría fijar w1 como parámetro a optimizar, \n",
    "# dado que la operación .to() hace que deje de ser un nodo hoja del grafo de derivación.\n",
    "# (No tenemos este problema cuando enviamos los parámetros de un modelo mediante model.to(device) \n",
    "# como hicimos en la práctica anterior)\n",
    "\n",
    "# Creamos un Optimizer que utilice el algoritmo SGD:\n",
    "optimizer = optim.SGD([w,], lr=0.001, weight_decay=0.001)\n",
    "\n",
    "for i in range(100):\n",
    "    b = a * w[0]\n",
    "    c = a * w[1]\n",
    "    d = w[2] * b + w[3] * c\n",
    "    l = torch.abs(10 - d)  # Cálculo del coste\n",
    "    print(f'l={l}')\n",
    "    # Tensorboard: Registramos el valor de coste en la iteración i\n",
    "    writer.add_scalar('loss', l.item(), global_step=i)\n",
    "    l.backward()\n",
    "    # Tensorboard: Registramos el valor de los gradientes de w:\n",
    "    print(f'w={w.cpu()}; w.grad={w.grad}')\n",
    "    writer.add_histogram('w1_grad', w.grad.cpu(), global_step=i)\n",
    "    writer.add_histogram('w', w.cpu(), global_step=i)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, en la carpeta *runs_folder* se habrá creado un fichero con nombre \"events.out.tfevents.XXX\", con la parte final del nombre correspondiendo a un identificador del modelo.\n",
    "\n",
    "Para analizar este log a continuación a través de la herramienta Tensorboard, deberemos:\n",
    "\n",
    "* Desde la terminal de linux, situarnos en la carpeta PATH_RUNS\n",
    "* Una vez en esta carpeta, escribimos el siguiente comando `tensorboard --logdir nombre_test`, que inicializará Tensorboard y analizará los *logs* almacenados dentro de la carpeta nombre_test (corresponderá a la ruta de *runs_folder*)\n",
    "* Abrimos una ventana de cualquier navegador y accedemos a la URL *localhost:6006* (o el número del puerto que nos indique la terminal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión reutilizaremos el bucle de la práctica anterior, con unas leves modificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Ejercicio 3**: </span> : Añade a la función *train* presentada a continuación, las líneas de código que sean necesarias para que, mediante Tensorboard, registres la siguiente información:\n",
    "\n",
    "* Valor de la función de coste tras cada epoch en Train y Val\n",
    "* Valor de la tasa de acierto tras cada epoch en Train y Val\n",
    "* Valor de los parámetros de cada capa al terminar cada epoch\n",
    "* Valor de los gradientes de los parámetros de cada capa al terminar cada epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: En la práctica anterior <span style=\"color:red\">había un error</span> en la definición de train(), dado que no se le enviaban el *criterion* a utilizar para calcular el coste de nuestro modelo ni el *optimizer* encargado de actualizar los valores de los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, val_loader=None, num_epochs=20, device='cuda'):\n",
    "\n",
    "    # Listas para generar logs durante el entrenamiento:\n",
    "    train_acc = []  \n",
    "    train_loss = []\n",
    "    \n",
    "    # Escritor \n",
    "    writer = SummaryWriter(log_dir=runs_folder)\n",
    "    \n",
    "    if val_loader is not None:\n",
    "        val_acc = []\n",
    "        val_loss = []\n",
    "\n",
    "    # Bucle de entrenamiento:\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        running_loss = 0.0  # Acumulamos el valor de coste obtenido tras cada epoch\n",
    "        \n",
    "        count_evaluated = 0\n",
    "        \n",
    "        count_correct = 0\n",
    "        \n",
    "        for batch_idx, data in enumerate(train_loader, 0):  \n",
    "            \n",
    "            model.train()  \n",
    "            \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            ### Fase de log ###\n",
    "            running_loss += loss.item()  # Acumulamos el error obtenido para utilizarlo\n",
    "                # a la hora de generar logs del proceso.\n",
    "                \n",
    "            # Contamos el número de ejemplos evaluados y acertados:\n",
    "            \n",
    "            count_evaluated += inputs.shape[0]\n",
    "            \n",
    "            count_correct += torch.sum(labels == torch.max(outputs, dim=1)[1])\n",
    "            \n",
    "        # Log del valor de la función de coste y accuracy\n",
    "        print('Training: [%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / (batch_idx+1)))\n",
    "        \n",
    "        # Apuntamos valor función coste \n",
    "        writer.add_scalar('Valor Coste Train', running_loss / (batch_idx+1), global_step = epoch + 1)\n",
    "        \n",
    "        train_loss.append(running_loss / (batch_idx+1))\n",
    "        # Almacenamos la accuracy al final de la epoch (en train)\n",
    "        \n",
    "        train_acc.append(float(count_correct) / count_evaluated)\n",
    "        \n",
    "        # Apuntamos valor función coste \n",
    "        writer.add_scalar('Valor Accuracy Train', float(count_correct) / count_evaluated, global_step = epoch + 1)\n",
    "        \n",
    "        # Apuntamos Log de los gradientes de cada parámetro\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'{name}.grad', param.grad, epoch + 1)\n",
    "        \n",
    "        ### Fase de validación ### \n",
    "        if val_loader is not None:\n",
    "            running_loss_val = 0.0\n",
    "            count_evaluated = 0\n",
    "            count_correct = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch_idx, data_val in enumerate(val_loader, 0):\n",
    "                    inputs_val, labels_val = data_val[0].to(device), data_val[1].to(device)\n",
    "                    outputs_val = model(inputs_val)\n",
    "                    loss = criterion(outputs_val, labels_val)\n",
    "                    running_loss_val += loss.item()\n",
    "                    count_evaluated += inputs_val.shape[0]\n",
    "                    count_correct += torch.sum(labels_val == torch.max(outputs_val, dim=1)[1])\n",
    "                # Presentamos el resumen de la validación de la epoch:\n",
    "                val_loss.append(running_loss_val / (val_batch_idx + 1))\n",
    "                \n",
    "                # Apuntamos valor función coste \n",
    "                writer.add_scalar('Valor Coste Val', running_loss_val / (val_batch_idx + 1), global_step = epoch + 1)\n",
    "                \n",
    "                acc_val = float(count_correct) / count_evaluated\n",
    "                \n",
    "                # Apuntamos valor función coste \n",
    "                writer.add_scalar('Valor Accuracy Val', float(count_correct) / count_evaluated, global_step = epoch + 1)\n",
    "                \n",
    "                print('Validation: epoch %d - acc: %.3f' %\n",
    "                            (epoch + 1, acc_val))\n",
    "                val_acc.append(acc_val)\n",
    "                \n",
    "        \n",
    "        # Apuntamos valor de los parámetros al finalizar la iteración\n",
    "        writer.add_scalar('Running Loss', running_loss, global_step = epoch + 1)\n",
    "        writer.add_scalar('Count Evaluated', count_evaluated, global_step = epoch + 1)\n",
    "        writer.add_scalar('Count Correct', count_correct, global_step = epoch + 1)\n",
    "        \n",
    "    # Devolvemos, tanto el modelo entrenado, como el diccionario con las estadísticas del entrenamiento\n",
    "    return model, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y aquí definimos la función de evaluación. \n",
    "\n",
    "**NOTA**: En la práctica anterior <span style=\"color:red\">había un error</span> en la definición de test(), dado que no se le enviaban el *criterion* a utilizar para calcular el coste de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device='cuda'):\n",
    "    with torch.no_grad():\n",
    "        number_samples = 0\n",
    "        number_correct = 0\n",
    "        running_loss_test = 0.0\n",
    "        for test_batch_idx, data_test in enumerate(test_loader, 0):\n",
    "            inputs_test, labels_test = data_test[0].to(device), data_test[1].long().to(device)\n",
    "            outputs_test = model(inputs_test)\n",
    "            loss = criterion(outputs_test, labels_test)\n",
    "            running_loss_test += loss.cpu().numpy()\n",
    "            # Accuracy:\n",
    "            _, outputs_class = torch.max(outputs_test, dim=1)\n",
    "            number_correct += torch.sum(outputs_class == labels_test).cpu().numpy()\n",
    "            number_samples += len(labels_test)\n",
    "        acc_test = number_correct / number_samples\n",
    "        print('Test - Accuracy: %.3f' % acc_test)\n",
    "        print('Test - CrossEntropy: %.3f' % (running_loss_test / (test_batch_idx+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en la práctica anterior, debemos fijar los hiperparámetros a utilizar para nuestro modelo, y proceder con su entrenamiento y evaluación. La parte final de esta práctica será recrear este proceso.\n",
    "\n",
    "<span style=\"color:green\">**Ejercicio 4**: </span> : Prepara los siguientes puntos:\n",
    "* Modelo LeNetPlus con los siguientes parámetros:\n",
    "    * Dos capas convolucionales con 64 filtros cada una\n",
    "    * Dos capas lineales ocultas con 384 y 192 neuronas respectivamente\n",
    "* Función de coste: Cross Entropy\n",
    "* Optimizador SGD con los siguientes hiperparámetros:\n",
    "    * learning_rate = 0.001\n",
    "    * momentum = 0.9\n",
    "    * weight_decay = 0.0001\n",
    "\n",
    "A continuación, entrena el modelo y evalúalo con el conjunto de test.\n",
    "\n",
    "Por último, analiza la evolución del entrenamiento utilizando la herramienta Tensorboard, en base a los valores registrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNetModel(\n",
      "  (conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool_1): PoolingLayer()\n",
      "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool_2): PoolingLayer()\n",
      "  (lin_1): Linear(in_features=4096, out_features=384, bias=True)\n",
      "  (lin_2): Linear(in_features=384, out_features=192, bias=True)\n",
      "  (salida): Linear(in_features=192, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creación del modelo\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LeNetModel(conv_filters=[64, 64], linear_sizes=[384, 192], num_classes=10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Definición de función de coste y optimizador\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [1,   704] loss: 2.016\n",
      "Validation: epoch 1 - acc: 0.371\n",
      "Training: [2,   704] loss: 1.657\n",
      "Validation: epoch 2 - acc: 0.425\n",
      "Training: [3,   704] loss: 1.495\n",
      "Validation: epoch 3 - acc: 0.486\n",
      "Training: [4,   704] loss: 1.386\n",
      "Validation: epoch 4 - acc: 0.517\n",
      "Training: [5,   704] loss: 1.308\n",
      "Validation: epoch 5 - acc: 0.543\n",
      "Training: [6,   704] loss: 1.247\n",
      "Validation: epoch 6 - acc: 0.562\n",
      "Training: [7,   704] loss: 1.192\n",
      "Validation: epoch 7 - acc: 0.583\n",
      "Training: [8,   704] loss: 1.144\n",
      "Validation: epoch 8 - acc: 0.595\n",
      "Training: [9,   704] loss: 1.103\n",
      "Validation: epoch 9 - acc: 0.608\n",
      "Training: [10,   704] loss: 1.062\n",
      "Validation: epoch 10 - acc: 0.617\n",
      "Training: [11,   704] loss: 1.019\n",
      "Validation: epoch 11 - acc: 0.627\n",
      "Training: [12,   704] loss: 0.986\n",
      "Validation: epoch 12 - acc: 0.638\n",
      "Training: [13,   704] loss: 0.951\n",
      "Validation: epoch 13 - acc: 0.647\n",
      "Training: [14,   704] loss: 0.925\n",
      "Validation: epoch 14 - acc: 0.661\n",
      "Training: [15,   704] loss: 0.893\n",
      "Validation: epoch 15 - acc: 0.662\n",
      "Training: [16,   704] loss: 0.870\n",
      "Validation: epoch 16 - acc: 0.660\n",
      "Training: [17,   704] loss: 0.844\n",
      "Validation: epoch 17 - acc: 0.676\n",
      "Training: [18,   704] loss: 0.818\n",
      "Validation: epoch 18 - acc: 0.682\n",
      "Training: [19,   704] loss: 0.802\n",
      "Validation: epoch 19 - acc: 0.673\n",
      "Training: [20,   704] loss: 0.779\n",
      "Validation: epoch 20 - acc: 0.687\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable LeNetModel object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, train_stats \u001b[38;5;241m=\u001b[39m train(model, train_loader, criterion, optimizer, val_loader, num_epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable LeNetModel object"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "model = train(model, train_loader, criterion, optimizer, val_loader, num_epochs= 20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar cosas\n",
    "train_loss = train_stats['train_loss']\n",
    "train_acc = train_stats['train_acc']\n",
    "val_loss = train_stats['val_loss']\n",
    "val_acc = train_stats['val_acc']\n",
    "\n",
    "# Error en entrenamiento:\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_loss)), train_loss)\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss')\n",
    "plt.show()\n",
    "# Error en validación:\n",
    "plt.figure()\n",
    "plt.plot(range(len(val_loss)), val_loss)\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation loss')\n",
    "plt.show()\n",
    "# Accuracy en entrenamiento y validación:\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_acc)), train_acc, 'r--', range(len(val_acc)), val_acc, 'b')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train set', 'Validation set'])\n",
    "plt.title('Model accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test(model, test_loader, criterion = criterion, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50b926a050cc029ac752863e4f86b7e2171f26cfdc0be8c315e356fc3ef03bad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
