{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we are going to implement different aggregating functions to create differente versions of pooling layers. Afterwards, the analysis of the results derived from different models will be performed, as well as the identification of different problems that will have appeared in the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Modifications of Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries that will be needed shall be imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # FFFFF\n",
    "\n",
    "# Data loading\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Auxiliary functions\n",
    "from torch.utils.tensorboard import SummaryWriter  # Used for Tensorboard logging\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor, ceil\n",
    "import datetime\n",
    "\n",
    "# Math\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we are going to establish a working hierarchy to have everything correctly organised:\n",
    "\n",
    "    ‚îú‚îÄ‚îÄ data               <- Directory for storing datasets\n",
    "    ‚îî‚îÄ‚îÄ reports            <- Outputs produced by the model\n",
    "     ¬†¬† ‚îú‚îÄ‚îÄ models         <- Trained and serialized models\n",
    "     ¬†¬† ‚îú‚îÄ‚îÄ results        <- Results obtained after training, testing on the test set\n",
    "     ¬†¬† ‚îî‚îÄ‚îÄ runs           <- Logs generated during training, interpretable by tensorboard (tensorboard --logdir [namedir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, we establish the following paths that shall be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proofs Folder Path: 2024_10_31__13_0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PATH_ROOT = os.path.join('.')\n",
    "# Path for data:\n",
    "PATH_DATA = os.path.join(PATH_ROOT, 'data')\n",
    "# Path for models:\n",
    "PATH_MODELS = os.path.join(PATH_ROOT, 'reports', 'models')\n",
    "# Path for results:\n",
    "PATH_RESULTS = os.path.join(PATH_ROOT, 'reports', 'results')\n",
    "# Path for runnings:\n",
    "PATH_RUNS = os.path.join(PATH_ROOT, 'reports', 'runs')\n",
    "\n",
    "# For each session we create a new folder from the datetime of its execution. \n",
    "date = datetime.datetime.now()\n",
    "test_name = str(date.year) + '_' + str(date.month) + '_' +  str(date.day) + '__' + str(date.hour) + '_' + str(date.minute)\n",
    "print('Proofs Folder Path: {}'.format(test_name))\n",
    "models_folder = os.path.join(PATH_MODELS, test_name)\n",
    "try:\n",
    "    os.mkdir(models_folder)\n",
    "except:\n",
    "    print(f'Folder {models_folder} already existed.')\n",
    "results_folder = os.path.join(PATH_RESULTS, test_name)\n",
    "try:\n",
    "    os.mkdir(results_folder)\n",
    "except:\n",
    "    print(f'Folder {results_folder} already existed.')\n",
    "runs_folder = os.path.join(PATH_RUNS, test_name)\n",
    "try:\n",
    "    os.mkdir(runs_folder)\n",
    "except:\n",
    "    print(f'Folder {runs_folder} already existed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the existence of a GPU to accelerate the calculations is checked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The existence of a GPU is proofed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data: Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the class lab, the data that will be used must be loaded. The very same dataset will be considered, and the same preprocessing will be applied before being sent to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data: Datasets and Dataloaders\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was also done in the class lab, the data loading is performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling method for train/val split\n",
    "train_proportion = 0.9  \n",
    "num_train = 50000  \n",
    "\n",
    "# Generate list with random indexes to choose the examples of each split\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(train_proportion * num_train))\n",
    "np.random.shuffle(indices)  # Random rearrange of indices\n",
    "\n",
    "train_idx, val_idx = indices[:split], indices[split:]\n",
    "# Generate torch.utils.data.SubsetRandomSampler to get the examples randomly from the given indexes. \n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = datasets.CIFAR10(root=PATH_DATA, train=True, \n",
    "                                 download=True, transform=train_transform)\n",
    "\n",
    "val_dataset = datasets.CIFAR10(root=PATH_DATA, train=True, \n",
    "                               download=True, transform=val_transform)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=PATH_DATA, train=False,\n",
    "                                download=True, transform=test_transform)\n",
    "\n",
    "# DataLoader definition:\n",
    "# Dataloaders take care of loading data in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                          sampler=train_sampler, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                        sampler=val_sampler, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once batches of examples can be correctly loaded to the training pipeline, it is possible now to proceed with the definition of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in the class lab, the LeNet-5 Model (basic architecture of CNN) will be considered. This architecture consists of: \n",
    "* Convolution Layers: With several filters; each of them produces a map of characteristics. \n",
    "* Pooling Layers: Reduces the dimensionality of the input due to an aggregating function. This part is the one that shall be modified by changing the aggregating function. \n",
    "* Lineal Layers: Related to a layer in a Neuronal Network. \n",
    "\n",
    "![Arquitectura LeNet-5](figures/LeNet-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Functions Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, several aggregating functions will be firstly mathematically explained and secondly programmed so that they could be used in the PoolingLayer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.0000, 0.3429],\n",
      "        [0.4739, 0.5834, 0.4028],\n",
      "        [0.6874, 0.5122, 0.6949]])\n",
      "tensor([0.4606, 0.4898, 0.6436], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "p = torch.randn([3,3], dtype=torch.float)\n",
    "#print(p)\n",
    "maximum = torch.max(p)\n",
    "minimum = torch.min(p)\n",
    "#print(maximum,minimum)\n",
    "p2 = (p-minimum)/(maximum-minimum)\n",
    "print(p2)\n",
    "#p3 = minimum + (maximum-minimum) * p2\n",
    "#print(p3)\n",
    "print(OWA(p2, -1, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arithmetic_mean(X, dim, keepdim):\n",
    "    return torch.mean(X, dim, keepdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OWA with Learnable Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OWA(X, dim, keepdim):\n",
    "    \n",
    "    weight = nn.Parameter(torch.empty(1, X.shape[dim]))\n",
    "            \n",
    "    stdv = 1. / math.sqrt(weight.size(1))\n",
    "    weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    tensor_ordered = torch.sort(X, descending = True)\n",
    "    weight_norm = torch.nn.functional.softmax(weight, dim = dim)\n",
    "    output = torch.sum(tensor_ordered[0] * weight_norm, dim = dim, keepdim = keepdim)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OWALayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features)))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        # Inicializamos los valores de self.weight y self.bias\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Calculamos el producto matricial entre input y el vector de pesos pero estilo OWA:\n",
    "        # f(x) = x_1 * w_1 + ... + x_n * w_n\n",
    "        tensor_orden = torch.sort(input, descending = True)\n",
    "        weight_norm = torch.nn.functional.softmax(self.weight)\n",
    "        output = torch.matmul(tensor_orden[0], weight_norm.t())\n",
    "        if self.bias is not None:\n",
    "            # f(x) = x_1 * w_1 + ... + x_n * w_n + bias\n",
    "            output += self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggPoolingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size, stride, padding= [0,0,0,0], function, dim = -1, keepdim = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Una tupla de 2 elementos con los tama√±os [ùëò1,ùëò2] de cada ventana a tratar\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Tupla de 2 elementos que indican el n√∫mero de elementos (en filas y columnas) que \n",
    "        # deben saltarse tras reducir cada ventana, hasta encontrar la siguiente a tratar.\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Tupla de 4 elementos de la forma [ùëùùëéùëë_ùëôùëíùëìùë°,ùëùùëéùëë_ùëüùëñùëî‚Ñéùë°,ùëùùëéùëë_ùë¢ùëù,ùëùùëéùëë_ùëëùëúùë§ùëõ] que indica el \n",
    "        # n√∫mero de nuevas filas o columnas a a√±adir a la entrada, previo a aplicar la agregaci√≥n.\n",
    "        self.padding = padding\n",
    "        \n",
    "        # Define function and characteristics\n",
    "        self.function = function\n",
    "        self.dim = dim\n",
    "        self.keepdim = keepdim\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # Normalize\n",
    "        maximum = torch.max(X)\n",
    "        minimum = torch.min(X)\n",
    "        X = (X-minimum)/(maximum-minimum)\n",
    "        \n",
    "        # A√±adir columnas/filas seg√∫n padding\n",
    "        X_pad = F.pad(X, pad=self.padding, mode='constant', value=0)\n",
    "        \n",
    "        # Vamos extrayendo las ventanas a agregar y coloc√°ndolas en filas\n",
    "        X_aux = X_pad.unfold(2, size=self.kernel_size[0], step=self.stride[0]).unfold(3, size=self.kernel_size[1], step=self.stride[1])\n",
    "        \n",
    "        # Ponemos el formato correcto\n",
    "        X_aux = X_aux.reshape([X_aux.shape[0], X_aux.shape[1], X_aux.shape[2], X_aux.shape[3], X_aux.shape[4] * X_aux.shape[5]]) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Agg Func\n",
    "        Y_temp = self.function(X_aux, dim = self.dim, keepdim = self.keepdim)\n",
    "        \n",
    "        # Denormalize \n",
    "        Y = minimum + (maximum-minimum) * Y_temp\n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Ejercicio 2**: </span> : Implementa el m√≥dulo LeNetModel que deber√° recrear la arquitectura LeNet-5. Los par√°metros de entrada del modelo ser√°n: \n",
    "\n",
    "* conv_filters: Una lista con el n√∫mero de filtros a aprender en cada capa de convoluci√≥n. Por defecto [64, 64].\n",
    "* linear_sizes: Una lista con el n√∫mero de neuronas de salida de cada capa lineal oculta del clasificador. Por defecto [384, 192].\n",
    "* num_clases: Entero que indica el n√∫mero de clases a predecir en nuestro problema. Por defecto 10.\n",
    "\n",
    "La arquitectura de la red consta de:\n",
    "\n",
    "* Convoluci√≥n con `conv_filters[0]` filtros de tama√±o [2, 2] y stride [1, 1].\n",
    "* Pooling con *kernel size* [2, 2] y stride [2, 2].\n",
    "* Convoluci√≥n con `conv_filters[1]` filtros de tama√±o [2, 2] y stride [1, 1].\n",
    "* Pooling con *kernel size* [2, 2] y stride [2, 2].\n",
    "* Capa oculta lineal con `conv_filters[1] * 8 * 8` neuronas de entrada y `linear_sizes[0]` neuronas de salida.\n",
    "* Capa oculta lineal con `linear_sizes[0]` neuronas de entrada y `linear_sizes[1]` neuronas de salida.\n",
    "* Capa de salida lineal con `linear_sizes[1]` neuronas de entrada y `num_classes` neuronas de salida.\n",
    "\n",
    "El modelo deber√° emplear la funci√≥n ReLU como funci√≥n de activaci√≥n. Adem√°s, antes de la primera capa oculta lineal, se deber√° convertir la salida $X$ de la capa anterior de tama√±o `[batch_size, conv_filters[1], 8, 8]` en un tensor de tama√±o `[batch_size, conv_filters[1] * 8, 8]` apto para servir de entrada a una capa *torch.nn.Linear*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetModel(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_filters=[64, 64], linear_sizes=[384, 192], num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv_filters = conv_filters\n",
    "        \n",
    "        self.linear_sizes = linear_sizes\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Primera Convoluci√≥n con conv_filters[0] filtros de tama√±o [3, 3] y stride [1, 1] y padding [1, 1].    \n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels = 3, out_channels = self.conv_filters[0], kernel_size = [3, 3], stride = [1, 1], padding = [1, 1], device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Primer Pooling con kernel size [2, 2] y stride [2, 2]\n",
    "        self.pool_1 = PoolingLayer(kernel_size = [2, 2], stride = [2, 2])\n",
    "        \n",
    "        # Segundo Convoluci√≥n con conv_filters[1] filtros de tama√±o [3, 3] y stride [1, 1] y padding [1, 1].\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels = self.conv_filters[0], out_channels = self.conv_filters[1], kernel_size = [3, 3], stride = [1, 1], padding = [1, 1], device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Segundo Pooling con kernel size [2, 2] y stride [2, 2]\n",
    "        self.pool_2 = PoolingLayer(kernel_size = [2, 2], stride = [2, 2])\n",
    "        \n",
    "        # Primera Capa oculta lineal con conv_filters[1] * 8 * 8 neuronas de entrada y linear_sizes[0] neuronas de salida.\n",
    "        self.lin_1 = torch.nn.Linear(in_features = self.conv_filters[1] * 8 * 8, out_features = self.linear_sizes[0], bias=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Segunda Capa oculta lineal con linear_sizes[0] neuronas de entrada y linear_sizes[1] neuronas de salida.\n",
    "        self.lin_2 = torch.nn.Linear(in_features = self.linear_sizes[0], out_features = self.linear_sizes[1], bias=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # Capa de salida lineal con linear_sizes[1] neuronas de entrada y num_classes neuronas de salida.\n",
    "        self.salida = torch.nn.Linear(in_features = self.linear_sizes[1], out_features = self.num_classes, bias=True, device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # print(X.shape)\n",
    "        \n",
    "        # Ejecutamos primera Convoluci√≥n \n",
    "        X_tras_conv_1 = self.conv_1(X)\n",
    "        #print(\"X_tras_conv_1.shape = \", X_tras_conv_1.shape)\n",
    "        \n",
    "        # Ejecutamos primer Pooling \n",
    "        X_tras_pool_1 = self.pool_1(X_tras_conv_1)\n",
    "        #print(\"X_tras_pool_1.shape = \", X_tras_pool_1.shape)\n",
    "        \n",
    "        # Ejecutamos segunda Convoluci√≥n\n",
    "        X_tras_conv_2 = self.conv_2(X_tras_pool_1)\n",
    "        #print(\"X_tras_conv_2.shape = \", X_tras_conv_2.shape)\n",
    "        \n",
    "        # Ejecutamos Segundo Pooling\n",
    "        X_tras_pool_2 = self.pool_2(X_tras_conv_2)\n",
    "        #print(\"X_tras_pool_2.shape = \", X_tras_pool_2.shape)\n",
    "        \n",
    "        # Antes de la primera capa oculta lineal, se deber√° convertir la salida ùëã de la capa anterior de tama√±o \n",
    "        # [batch_size, conv_filters[1], 8, 8] en un tensor de tama√±o [batch_size, conv_filters[1] * 8 * 8]\n",
    "        X_tras_rshp = X_tras_pool_2.reshape([X_tras_pool_2.shape[0], X_tras_pool_2.shape[1] * X_tras_pool_2.shape[2] * X_tras_pool_2.shape[3]])\n",
    "        #print(\"X_tras_rshp.shape = \",X_tras_rshp.shape)\n",
    "        \n",
    "        # Ejecutamos 1¬∫ Capa oculta lineal.\n",
    "        X_tras_lin_1 = self.lin_1(X_tras_rshp)\n",
    "        #print(\"X_tras_lin_1.shape = \", X_tras_lin_1.shape)\n",
    "        \n",
    "        # Le aplicamos ReLU\n",
    "        X_tras_relu_1 = F.relu(X_tras_lin_1)\n",
    "        #print(\"X_tras_relu_1.shape = \",X_tras_relu_1.shape)\n",
    "        \n",
    "        # Ejecutamos 2¬∫ capa oculta lineal \n",
    "        X_tras_lin_2 = self.lin_2(X_tras_relu_1)\n",
    "        #print(\"X_tras_lin_2.shape = \", X_tras_lin_2.shape)\n",
    "        \n",
    "        # Le aplicamos ReLU\n",
    "        X_tras_relu_2 = F.relu(X_tras_lin_2)\n",
    "        #print(\"X_tras_relu_2.shape = \", X_tras_relu_2.shape)\n",
    "        \n",
    "        # Ejecutamos Capa de salida lineal .\n",
    "        X_salida = self.salida(X_tras_relu_2)\n",
    "        #print(\"X_salida.shape = \", X_salida.shape)\n",
    "        \n",
    "        return X_salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de pasar a plantear el bucle de entrenamiento de nuestro nuevo modelo, vamos a presentar el modo de loggear informaci√≥n de nuestro modelo de modo que sea compatible con la herramienta [Tensorboard](https://www.tensorflow.org/tensorboard?hl=es-419). Aunque inicialmente se trataba de una herramienta desarrollada para trabajar con el framework Tensorflow (otra alternativa a PyTorch para Deep Learning), actualmente [es compatible con PyTorch](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "\n",
    "Tensorboard es una herramienta de visualizaci√≥n muy potente que permite, entre otras:\n",
    "\n",
    "* Registrar la evaluaci√≥n de m√©tricas de aprendizaje (como coste o tasa de acierto): Permite medir f√°cilmente el rendimiento del modelo en entrenamiento y compararlo con el de otras variantes del mismo u otros modelos.\n",
    "* Registrar distribuciones de valores (como las de los par√°metros del modelo o sus gradientes): Facilita localizar problemas de entrenamiento del modelo, como \"gradientes desvanecientes\" o \"gradientes explosivos\".\n",
    "* Proyectar datos transformados a un espacio dimensional mejor (mediante algoritmos como PCA o T-SNE): Se puede utilizar sobre los vectores de caracter√≠sticas extra√≠dos por el modelo a distintos niveles para comprender c√≥mo diferencia el modelo entre las distintas clases. Veremos su uso en futuras pr√°cticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comenzar ilustrando este proceso con un proceso muy simple, antes de incorporarlo a nuestra pipeline de entrenamiento.\n",
    "\n",
    "En PyTorch, la forma m√°s f√°cil de registrar informaci√≥n para su posterior an√°lisis con la herramienta, es a trav√©s del objeto *torch.utils.tensorboard.SummaryWriter*. Los pasos a seguir son:\n",
    "\n",
    "* Crear un *SummaryWriter* indic√°ndole la ruta en la que almacenar los logs:\n",
    "\n",
    "    `writer = SummaryWriter(log_dir=runs_folder)`\n",
    "\n",
    "* Para registrar un valor escalar (por ejemplo el coste de nuestra funci√≥n o la tasa de acierto), utilizaremos:\n",
    "\n",
    "    `writer.add_scalar(tag, scalar_value, global_step)`\n",
    "    * *tag* ser√° un *string* con el que se identificar√° la variable a registrar.\n",
    "    * *scalar_value* ser√° un *float* que contendr√° el valor de esa variable en la iteraci√≥n que estamos registrando.\n",
    "    * *global_step* ser√° un *int* que indica la iteraci√≥n que estamos registrando.\n",
    "\n",
    "Para ilustrar este proceso vamos a plantear el ejemplo que vimos en el Tutorial para optimizar los par√°metros de la funci√≥n:\n",
    "\n",
    "$$f(a) = w_3 * (w_1 * a) + w_4 * (w_2 * a)$$\n",
    "\n",
    "En esta ocasi√≥n, no obstante, vamos a utilizar algunos de los conceptos que ya conocemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l=tensor([32.], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-2.,  2., -4.,  3.], grad_fn=<ToCopyBackward0>); w.grad=tensor([-12.,   9.,  -6.,   6.], device='cuda:0')\n",
      "l=tensor([31.7033], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.9880,  1.9910, -3.9940,  2.9940], grad_fn=<ToCopyBackward0>); w.grad=tensor([-23.9820,  17.9820, -11.9640,  11.9730], device='cuda:0')\n",
      "l=tensor([31.1130], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.9640,  1.9730, -3.9820,  2.9820], grad_fn=<ToCopyBackward0>); w.grad=tensor([-35.9281,  26.9281, -17.8560,  17.8920], device='cuda:0')\n",
      "l=tensor([30.2351], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.9281,  1.9461, -3.9642,  2.9641], grad_fn=<ToCopyBackward0>); w.grad=tensor([-47.8206,  35.8204, -23.6403,  23.7303], device='cuda:0')\n",
      "l=tensor([29.0784], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.8803,  1.9103, -3.9405,  2.9404], grad_fn=<ToCopyBackward0>); w.grad=tensor([-59.6421,  44.6416, -29.2811,  29.4611], device='cuda:0')\n",
      "l=tensor([27.6547], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.8206,  1.8656, -3.9112,  2.9109], grad_fn=<ToCopyBackward0>); w.grad=tensor([-71.3759,  53.3744, -34.7429,  35.0579], device='cuda:0')\n",
      "l=tensor([25.9781], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.7492,  1.8122, -3.8765,  2.8759], grad_fn=<ToCopyBackward0>); w.grad=tensor([-83.0053,  62.0020, -39.9906,  40.4947], device='cuda:0')\n",
      "l=tensor([24.0652], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.6662,  1.7502, -3.8365,  2.8354], grad_fn=<ToCopyBackward0>); w.grad=tensor([-94.5148,  70.5081, -44.9893,  45.7454], device='cuda:0')\n",
      "l=tensor([21.9349], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.5717,  1.6797, -3.7915,  2.7896], grad_fn=<ToCopyBackward0>); w.grad=tensor([-105.8893,   78.8770,  -49.7045,   50.7846], device='cuda:0')\n",
      "l=tensor([19.6078], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.4658,  1.6008, -3.7418,  2.7388], grad_fn=<ToCopyBackward0>); w.grad=tensor([-117.1147,   87.0935,  -54.1020,   55.5871], device='cuda:0')\n",
      "l=tensor([17.1062], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.3487,  1.5138, -3.6877,  2.6832], grad_fn=<ToCopyBackward0>); w.grad=tensor([-128.1778,   95.1432,  -58.1481,   60.1284], device='cuda:0')\n",
      "l=tensor([14.4534], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.2205,  1.4186, -3.6295,  2.6231], grad_fn=<ToCopyBackward0>); w.grad=tensor([-139.0664,  103.0126,  -61.8097,   64.3842], device='cuda:0')\n",
      "l=tensor([11.6738], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-1.0815,  1.3156, -3.5677,  2.5587], grad_fn=<ToCopyBackward0>); w.grad=tensor([-149.7696,  110.6887,  -65.0541,   68.3310], device='cuda:0')\n",
      "l=tensor([8.7923], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.9317,  1.2049, -3.5027,  2.4904], grad_fn=<ToCopyBackward0>); w.grad=tensor([-160.2776,  118.1599,  -67.8492,   71.9457], device='cuda:0')\n",
      "l=tensor([5.8337], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7714,  1.0867, -3.4348,  2.4184], grad_fn=<ToCopyBackward0>); w.grad=tensor([-170.5820,  125.4153,  -70.1634,   75.2059], device='cuda:0')\n",
      "l=tensor([2.8226], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.6008,  0.9613, -3.3646,  2.3432], grad_fn=<ToCopyBackward0>); w.grad=tensor([-180.6760,  132.4450,  -71.9659,   78.0899], device='cuda:0')\n",
      "l=tensor([0.2171], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.4202,  0.8289, -3.2927,  2.2651], grad_fn=<ToCopyBackward0>); w.grad=tensor([-170.7979,  125.6495,  -70.7054,   75.6033], device='cuda:0')\n",
      "l=tensor([2.9705], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.2494,  0.7032, -3.2220,  2.1895], grad_fn=<ToCopyBackward0>); w.grad=tensor([-161.1320,  119.0809,  -69.9574,   73.4936], device='cuda:0')\n",
      "l=tensor([5.4575], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.0882,  0.5842, -3.1520,  2.1160], grad_fn=<ToCopyBackward0>); w.grad=tensor([-151.6760,  112.7328,  -69.6927,   71.7411], device='cuda:0')\n",
      "l=tensor([7.6956], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.0635,  0.4714, -3.0823,  2.0443], grad_fn=<ToCopyBackward0>); w.grad=tensor([-142.4291,  106.5999,  -69.8830,   70.3269], device='cuda:0')\n",
      "l=tensor([9.7002], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2059,  0.3648, -3.0124,  1.9740], grad_fn=<ToCopyBackward0>); w.grad=tensor([-133.3918,  100.6780,  -70.5007,   69.2324], device='cuda:0')\n",
      "l=tensor([11.4850], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.3393,  0.2641, -2.9419,  1.9047], grad_fn=<ToCopyBackward0>); w.grad=tensor([-124.5660,   94.9638,  -71.5185,   68.4400], device='cuda:0')\n",
      "l=tensor([13.0623], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.4638,  0.1692, -2.8704,  1.8363], grad_fn=<ToCopyBackward0>); w.grad=tensor([-115.9548,   89.4549,  -72.9100,   67.9325], device='cuda:0')\n",
      "l=tensor([14.4430], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.5798,  0.0797, -2.7975,  1.7684], grad_fn=<ToCopyBackward0>); w.grad=tensor([-107.5623,   84.1498,  -74.6494,   67.6933], device='cuda:0')\n",
      "l=tensor([15.6373], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.6874, -0.0044, -2.7228,  1.7007], grad_fn=<ToCopyBackward0>); w.grad=tensor([-99.3938,  79.0478, -76.7115,  67.7066], device='cuda:0')\n",
      "l=tensor([16.6545], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.7867, -0.0835, -2.6461,  1.6330], grad_fn=<ToCopyBackward0>); w.grad=tensor([-91.4555,  74.1489, -79.0717,  67.9570], device='cuda:0')\n",
      "l=tensor([17.5032], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.8782, -0.1576, -2.5670,  1.5650], grad_fn=<ToCopyBackward0>); w.grad=tensor([-83.7543,  69.4539, -81.7063,  68.4299], device='cuda:0')\n",
      "l=tensor([18.1919], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.9620, -0.2271, -2.4853,  1.4966], grad_fn=<ToCopyBackward0>); w.grad=tensor([-76.2983,  64.9642, -84.5922,  69.1112], device='cuda:0')\n",
      "l=tensor([18.7284], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.0383, -0.2920, -2.4007,  1.4275], grad_fn=<ToCopyBackward0>); w.grad=tensor([-69.0961,  60.6819, -87.7070,  69.9873], device='cuda:0')\n",
      "l=tensor([19.1205], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1073, -0.3527, -2.3130,  1.3575], grad_fn=<ToCopyBackward0>); w.grad=tensor([-62.1570,  56.6095, -91.0290,  71.0455], device='cuda:0')\n",
      "l=tensor([19.3757], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1695, -0.4093, -2.2220,  1.2864], grad_fn=<ToCopyBackward0>); w.grad=tensor([-55.4910,  52.7502, -94.5375,  72.2735], device='cuda:0')\n",
      "l=tensor([19.5015], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.2250, -0.4621, -2.1275,  1.2141], grad_fn=<ToCopyBackward0>); w.grad=tensor([-49.1086,  49.1078, -98.2125,  73.6598], device='cuda:0')\n",
      "l=tensor([19.5054], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.2741, -0.5112, -2.0292,  1.1405], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -43.0208,   45.6864, -102.0348,   75.1933], device='cuda:0')\n",
      "l=tensor([19.3948], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3171, -0.5569, -1.9272,  1.0653], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -37.2392,   42.4905, -105.9862,   76.8640], device='cuda:0')\n",
      "l=tensor([19.1771], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3544, -0.5994, -1.8212,  0.9884], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -31.7755,   39.5252, -110.0493,   78.6621], device='cuda:0')\n",
      "l=tensor([18.8595], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3861, -0.6389, -1.7112,  0.9098], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -26.6420,   36.7960, -114.2077,   80.5788], device='cuda:0')\n",
      "l=tensor([18.4493], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4128, -0.6757, -1.5970,  0.8292], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -21.8511,   34.3084, -118.4460,   82.6058], device='cuda:0')\n",
      "l=tensor([17.9535], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4346, -0.7100, -1.4785,  0.7466], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -17.4155,   32.0687, -122.7498,   84.7358], device='cuda:0')\n",
      "l=tensor([17.3792], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4520, -0.7421, -1.3558,  0.6618], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -13.3482,   30.0832, -127.1060,   86.9620], device='cuda:0')\n",
      "l=tensor([16.7330], device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=tensor([ 1.4654, -0.7721, -1.2287,  0.5749], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -9.6623,   28.3586, -131.5021,   89.2785], device='cuda:0')\n",
      "l=tensor([16.0212], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4750, -0.8005, -1.0972,  0.4856], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -6.3708,   26.9018, -135.9273,   91.6800], device='cuda:0')\n",
      "l=tensor([15.2497], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4814, -0.8274, -0.9612,  0.3939], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -3.4871,   25.7200, -140.3715,   94.1622], device='cuda:0')\n",
      "l=tensor([14.4238], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4849, -0.8531, -0.8209,  0.2998], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -1.0246,   24.8208, -144.8262,   96.7216], device='cuda:0')\n",
      "l=tensor([13.5483], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4859, -0.8779, -0.6760,  0.2030], grad_fn=<ToCopyBackward0>); w.grad=tensor([   1.0035,   24.2117, -149.2840,   99.3554], device='cuda:0')\n",
      "l=tensor([12.6271], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4849, -0.9022, -0.5267,  0.1037], grad_fn=<ToCopyBackward0>); w.grad=tensor([   2.5837,   23.9007, -153.7387,  102.0619], device='cuda:0')\n",
      "l=tensor([11.6632], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4823, -0.9261, -0.3730,  0.0016], grad_fn=<ToCopyBackward0>); w.grad=tensor([   3.7027,   23.8958, -158.1857,  104.8401], device='cuda:0')\n",
      "l=tensor([10.6587], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4786, -0.9500, -0.2148, -0.1032], grad_fn=<ToCopyBackward0>); w.grad=tensor([   4.3472,   24.2055, -162.6216,  107.6899], device='cuda:0')\n",
      "l=tensor([9.6144], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4743, -0.9742, -0.0522, -0.2109], grad_fn=<ToCopyBackward0>); w.grad=tensor([   4.5038,   24.8383, -167.0444,  110.6124], device='cuda:0')\n",
      "l=tensor([8.5300], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4698, -0.9990,  0.1148, -0.3215], grad_fn=<ToCopyBackward0>); w.grad=tensor([   4.1592,   25.8028, -171.4538,  113.6094], device='cuda:0')\n",
      "l=tensor([7.4034], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4656, -1.0248,  0.2863, -0.4351], grad_fn=<ToCopyBackward0>); w.grad=tensor([   3.3003,   27.1083, -175.8506,  116.6837], device='cuda:0')\n",
      "l=tensor([6.2312], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4623, -1.0519,  0.4622, -0.5518], grad_fn=<ToCopyBackward0>); w.grad=tensor([   1.9138,   28.7637, -180.2376,  119.8395], device='cuda:0')\n",
      "l=tensor([5.0080], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4604, -1.0807,  0.6424, -0.6717], grad_fn=<ToCopyBackward0>); w.grad=tensor([-1.3324e-02,  3.0779e+01, -1.8462e+02,  1.2308e+02], device='cuda:0')\n",
      "l=tensor([3.7268], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4604, -1.1114,  0.8270, -0.7947], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -2.4944,   33.1629, -189.0000,  126.4158], device='cuda:0')\n",
      "l=tensor([2.3780], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4629, -1.1446,  1.0160, -0.9212], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -5.5424,   35.9264, -193.3887,  129.8496], device='cuda:0')\n",
      "l=tensor([0.9500], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4684, -1.1805,  1.2094, -1.0510], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -9.1706,   39.0794, -197.7940,  133.3912], device='cuda:0')\n",
      "l=tensor([0.5713], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4776, -1.2196,  1.4072, -1.1844], grad_fn=<ToCopyBackward0>); w.grad=tensor([  -4.9490,   35.5262, -193.3612,  129.7324], device='cuda:0')\n",
      "l=tensor([2.0669], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4826, -1.2551,  1.6005, -1.3141], grad_fn=<ToCopyBackward0>); w.grad=tensor([-1.4735e-01,  3.1584e+01, -1.8891e+02,  1.2597e+02], device='cuda:0')\n",
      "l=tensor([3.5187], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4827, -1.2867,  1.7895, -1.4401], grad_fn=<ToCopyBackward0>); w.grad=tensor([   5.2210,   27.2636, -184.4654,  122.1068], device='cuda:0')\n",
      "l=tensor([4.9074], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4775, -1.3140,  1.9739, -1.5622], grad_fn=<ToCopyBackward0>); w.grad=tensor([  11.1428,   22.5770, -180.0329,  118.1649], device='cuda:0')\n",
      "l=tensor([6.2130], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4663, -1.3366,  2.1540, -1.6804], grad_fn=<ToCopyBackward0>); w.grad=tensor([  17.6047,   17.5359, -175.6339,  114.1552], device='cuda:0')\n",
      "l=tensor([7.4146], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4487, -1.3541,  2.3296, -1.7945], grad_fn=<ToCopyBackward0>); w.grad=tensor([  24.5934,   12.1524, -171.2877,  110.0930], device='cuda:0')\n",
      "l=tensor([8.4912], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.4241, -1.3662,  2.5009, -1.9046], grad_fn=<ToCopyBackward0>); w.grad=tensor([  32.0960,    6.4385, -167.0153,  105.9942], device='cuda:0')\n",
      "l=tensor([9.4211], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3920, -1.3727,  2.6679, -2.0106], grad_fn=<ToCopyBackward0>); w.grad=tensor([  40.0997,    0.4067, -162.8392,  101.8762], device='cuda:0')\n",
      "l=tensor([10.1827], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3519, -1.3731,  2.8307, -2.1125], grad_fn=<ToCopyBackward0>); w.grad=tensor([  48.5919,   -5.9307, -158.7834,   97.7570], device='cuda:0')\n",
      "l=tensor([10.7542], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.3033, -1.3671,  2.9895, -2.2102], grad_fn=<ToCopyBackward0>); w.grad=tensor([  57.5604,  -12.5614, -154.8733,   93.6555], device='cuda:0')\n",
      "l=tensor([11.1140], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.2458, -1.3546,  3.1444, -2.3039], grad_fn=<ToCopyBackward0>); w.grad=tensor([  66.9935,  -19.4730, -151.1360,   89.5918], device='cuda:0')\n",
      "l=tensor([11.2408], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1788, -1.3351,  3.2955, -2.3935], grad_fn=<ToCopyBackward0>); w.grad=tensor([  76.8800,  -26.6534, -147.5996,   85.5864], device='cuda:0')\n",
      "l=tensor([11.1132], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.1019, -1.3085,  3.4431, -2.4791], grad_fn=<ToCopyBackward0>); w.grad=tensor([  87.2093,  -34.0906, -144.2939,   81.6611], device='cuda:0')\n",
      "l=tensor([10.7102], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 1.0147, -1.2744,  3.5874, -2.5607], grad_fn=<ToCopyBackward0>); w.grad=tensor([  97.9715,  -41.7727, -141.2498,   77.8380], device='cuda:0')\n",
      "l=tensor([10.0112], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.9167, -1.2326,  3.7286, -2.6385], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 109.1574,  -49.6883, -138.4996,   74.1402], device='cuda:0')\n",
      "l=tensor([8.9954], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.8076, -1.1829,  3.8671, -2.7127], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 120.7588,  -57.8264, -136.0769,   70.5915], device='cuda:0')\n",
      "l=tensor([7.6425], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.6868, -1.1251,  4.0032, -2.7833], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 132.7684,  -66.1762, -134.0165,   67.2163], device='cuda:0')\n",
      "l=tensor([5.9317], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.5540, -1.0589,  4.1372, -2.8505], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 145.1801,  -74.7277, -132.3544,   64.0396], device='cuda:0')\n",
      "l=tensor([3.8421], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.4089, -0.9842,  4.2696, -2.9145], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 157.9888,  -83.4713, -131.1278,   61.0871], device='cuda:0')\n",
      "l=tensor([1.3524], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2509, -0.9007,  4.4007, -2.9756], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 171.1909,  -92.3981, -130.3752,   58.3850], device='cuda:0')\n",
      "l=tensor([1.5598], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.0797, -0.8083,  4.5311, -3.0340], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 157.5977,  -83.2961, -130.6142,   60.8099], device='cuda:0')\n",
      "l=tensor([4.3585], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.0779, -0.7250,  4.6617, -3.0948], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 143.6127,  -74.0117, -130.3804,   62.9849], device='cuda:0')\n",
      "l=tensor([7.0178], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.2215, -0.6510,  4.7920, -3.1578], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 129.2365,  -64.5384, -129.7159,   64.9378], device='cuda:0')\n",
      "l=tensor([9.5093], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.3508, -0.5864,  4.9218, -3.2227], grad_fn=<ToCopyBackward0>); w.grad=tensor([ 114.4712,  -54.8702, -128.6635,   66.6972], device='cuda:0')\n",
      "l=tensor([11.8032], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.4652, -0.5316,  5.0504, -3.2894], grad_fn=<ToCopyBackward0>); w.grad=tensor([  99.3200,  -45.0020, -127.2678,   68.2919], device='cuda:0')\n",
      "l=tensor([13.8680], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.5646, -0.4866,  5.1777, -3.3577], grad_fn=<ToCopyBackward0>); w.grad=tensor([  83.7869,  -34.9289, -125.5741,   69.7516], device='cuda:0')\n",
      "l=tensor([15.6710], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.6483, -0.4516,  5.3033, -3.4274], grad_fn=<ToCopyBackward0>); w.grad=tensor([  67.8772,  -24.6466, -123.6291,   71.1066], device='cuda:0')\n",
      "l=tensor([17.1789], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7162, -0.4270,  5.4269, -3.4985], grad_fn=<ToCopyBackward0>); w.grad=tensor([  51.5966,  -14.1510, -121.4804,   72.3876], device='cuda:0')\n",
      "l=tensor([18.3576], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7678, -0.4128,  5.5484, -3.5709], grad_fn=<ToCopyBackward0>); w.grad=tensor([  34.9515,   -3.4382, -119.1770,   73.6261], device='cuda:0')\n",
      "l=tensor([19.1728], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8028, -0.4094,  5.6675, -3.6446], grad_fn=<ToCopyBackward0>); w.grad=tensor([  17.9489,    7.4955, -116.7687,   74.8543], device='cuda:0')\n",
      "l=tensor([19.5899], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8207, -0.4169,  5.7843, -3.7194], grad_fn=<ToCopyBackward0>); w.grad=tensor([   0.5961,   18.6537, -114.3065,   76.1050], device='cuda:0')\n",
      "l=tensor([19.5743], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8213, -0.4356,  5.8986, -3.7955], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -17.0997,   30.0402, -111.8426,   77.4117], device='cuda:0')\n",
      "l=tensor([19.0913], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.8042, -0.4656,  6.0104, -3.8729], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -35.1309,   41.6590, -109.4300,   78.8085], device='cuda:0')\n",
      "l=tensor([18.1064], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7691, -0.5073,  6.1198, -3.9517], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -53.4905,   53.5141, -107.1227,   80.3303], device='cuda:0')\n",
      "l=tensor([16.5847], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.7156, -0.5608,  6.2270, -4.0320], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -72.1714,   65.6103, -104.9760,   82.0126], device='cuda:0')\n",
      "l=tensor([14.4913], device='cuda:0', grad_fn=<AbsBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=tensor([-0.6434, -0.6264,  6.3319, -4.1141], grad_fn=<ToCopyBackward0>); w.grad=tensor([ -91.1672,   77.9524, -103.0457,   83.8917], device='cuda:0')\n",
      "l=tensor([11.7909], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.5522, -0.7043,  6.4350, -4.1979], grad_fn=<ToCopyBackward0>); w.grad=tensor([-110.4721,   90.5463, -101.3890,   86.0047], device='cuda:0')\n",
      "l=tensor([8.4472], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.4418, -0.7949,  6.5364, -4.2839], grad_fn=<ToCopyBackward0>); w.grad=tensor([-130.0811,  103.3981, -100.0636,   88.3893], device='cuda:0')\n",
      "l=tensor([4.4230], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.3117, -0.8983,  6.6364, -4.3723], grad_fn=<ToCopyBackward0>); w.grad=tensor([-149.9904,  116.5151,  -99.1286,   91.0842], device='cuda:0')\n",
      "l=tensor([0.3207], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.1617, -1.0148,  6.7355, -4.4634], grad_fn=<ToCopyBackward0>); w.grad=tensor([-129.7838,  103.1248,  -99.6137,   88.0398], device='cuda:0')\n",
      "l=tensor([4.6098], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([-0.0319, -1.1179,  6.8351, -4.5514], grad_fn=<ToCopyBackward0>); w.grad=tensor([-109.2784,   89.4705,  -99.7094,   84.6861], device='cuda:0')\n",
      "l=tensor([8.4021], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.0774, -1.2074,  6.9348, -4.6361], grad_fn=<ToCopyBackward0>); w.grad=tensor([-88.4738,  75.5621, -99.4773,  81.0639], device='cuda:0')\n",
      "l=tensor([11.6552], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.1658, -1.2829,  7.0343, -4.7172], grad_fn=<ToCopyBackward0>); w.grad=tensor([-67.3709,  61.4106, -98.9798,  77.2151], device='cuda:0')\n",
      "l=tensor([14.3266], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2332, -1.3444,  7.1333, -4.7944], grad_fn=<ToCopyBackward0>); w.grad=tensor([-45.9710,  47.0274, -98.2802,  73.1820], device='cuda:0')\n",
      "l=tensor([16.3745], device='cuda:0', grad_fn=<AbsBackward0>)\n",
      "w=tensor([ 0.2792, -1.3914,  7.2316, -4.8676], grad_fn=<ToCopyBackward0>); w.grad=tensor([-24.2763,  32.4247, -97.4427,  69.0079], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard: Inicializamos nuestro objeto SummaryWriter con la ruta del test actual:\n",
    "writer = SummaryWriter(log_dir=runs_folder)\n",
    "\n",
    "# Inicializamos las variables a tratar:\n",
    "a = torch.tensor([3], dtype=torch.float).to(device)\n",
    "# w = torch.tensor([-.2, .2, -.4, .3], dtype=torch.float, device=device, requires_grad=True)\n",
    "w = nn.Parameter(torch.tensor([-2, 2, -4, 3], dtype=torch.float, device=device))\n",
    "# Nota: Creamos el tensor directamente en \"device\"\n",
    "# w = torch.tensor(...).to(device) no nos permitir√≠a fijar w1 como par√°metro a optimizar, \n",
    "# dado que la operaci√≥n .to() hace que deje de ser un nodo hoja del grafo de derivaci√≥n.\n",
    "# (No tenemos este problema cuando enviamos los par√°metros de un modelo mediante model.to(device) \n",
    "# como hicimos en la pr√°ctica anterior)\n",
    "\n",
    "# Creamos un Optimizer que utilice el algoritmo SGD:\n",
    "optimizer = optim.SGD([w,], lr=0.001, weight_decay=0.001)\n",
    "\n",
    "for i in range(100):\n",
    "    b = a * w[0]\n",
    "    c = a * w[1]\n",
    "    d = w[2] * b + w[3] * c\n",
    "    l = torch.abs(10 - d)  # C√°lculo del coste\n",
    "    print(f'l={l}')\n",
    "    # Tensorboard: Registramos el valor de coste en la iteraci√≥n i\n",
    "    writer.add_scalar('loss', l.item(), global_step=i)\n",
    "    l.backward()\n",
    "    # Tensorboard: Registramos el valor de los gradientes de w:\n",
    "    print(f'w={w.cpu()}; w.grad={w.grad}')\n",
    "    writer.add_histogram('w1_grad', w.grad.cpu(), global_step=i)\n",
    "    writer.add_histogram('w', w.cpu(), global_step=i)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, en la carpeta *runs_folder* se habr√° creado un fichero con nombre \"events.out.tfevents.XXX\", con la parte final del nombre correspondiendo a un identificador del modelo.\n",
    "\n",
    "Para analizar este log a continuaci√≥n a trav√©s de la herramienta Tensorboard, deberemos:\n",
    "\n",
    "* Desde la terminal de linux, situarnos en la carpeta PATH_RUNS\n",
    "* Una vez en esta carpeta, escribimos el siguiente comando `tensorboard --logdir nombre_test`, que inicializar√° Tensorboard y analizar√° los *logs* almacenados dentro de la carpeta nombre_test (corresponder√° a la ruta de *runs_folder*)\n",
    "* Abrimos una ventana de cualquier navegador y accedemos a la URL *localhost:6006* (o el n√∫mero del puerto que nos indique la terminal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasi√≥n reutilizaremos el bucle de la pr√°ctica anterior, con unas leves modificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">**Ejercicio 3**: </span> : A√±ade a la funci√≥n *train* presentada a continuaci√≥n, las l√≠neas de c√≥digo que sean necesarias para que, mediante Tensorboard, registres la siguiente informaci√≥n:\n",
    "\n",
    "* Valor de la funci√≥n de coste tras cada epoch en Train y Val\n",
    "* Valor de la tasa de acierto tras cada epoch en Train y Val\n",
    "* Valor de los par√°metros de cada capa al terminar cada epoch\n",
    "* Valor de los gradientes de los par√°metros de cada capa al terminar cada epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: En la pr√°ctica anterior <span style=\"color:red\">hab√≠a un error</span> en la definici√≥n de train(), dado que no se le enviaban el *criterion* a utilizar para calcular el coste de nuestro modelo ni el *optimizer* encargado de actualizar los valores de los par√°metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, val_loader=None, num_epochs=20, device='cuda'):\n",
    "\n",
    "    # Listas para generar logs durante el entrenamiento:\n",
    "    train_acc = []  \n",
    "    train_loss = []\n",
    "    \n",
    "    # Escritor \n",
    "    writer = SummaryWriter(log_dir=runs_folder)\n",
    "    \n",
    "    if val_loader is not None:\n",
    "        val_acc = []\n",
    "        val_loss = []\n",
    "\n",
    "    # Bucle de entrenamiento:\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        running_loss = 0.0  # Acumulamos el valor de coste obtenido tras cada epoch\n",
    "        \n",
    "        count_evaluated = 0\n",
    "        \n",
    "        count_correct = 0\n",
    "        \n",
    "        for batch_idx, data in enumerate(train_loader, 0):  \n",
    "            \n",
    "            model.train()  \n",
    "            \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            ### Fase de log ###\n",
    "            running_loss += loss.item()  # Acumulamos el error obtenido para utilizarlo\n",
    "                # a la hora de generar logs del proceso.\n",
    "                \n",
    "            # Contamos el n√∫mero de ejemplos evaluados y acertados:\n",
    "            \n",
    "            count_evaluated += inputs.shape[0]\n",
    "            \n",
    "            count_correct += torch.sum(labels == torch.max(outputs, dim=1)[1])\n",
    "            \n",
    "        # Log del valor de la funci√≥n de coste y accuracy\n",
    "        print('Training: [%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / (batch_idx+1)))\n",
    "        \n",
    "        # Apuntamos valor funci√≥n coste \n",
    "        writer.add_scalar('Valor Coste Train', running_loss / (batch_idx+1), global_step = epoch + 1)\n",
    "        \n",
    "        train_loss.append(running_loss / (batch_idx+1))\n",
    "        # Almacenamos la accuracy al final de la epoch (en train)\n",
    "        \n",
    "        train_acc.append(float(count_correct) / count_evaluated)\n",
    "        \n",
    "        # Apuntamos valor funci√≥n coste \n",
    "        writer.add_scalar('Valor Accuracy Train', float(count_correct) / count_evaluated, global_step = epoch + 1)\n",
    "        \n",
    "        # Apuntamos Log de los gradientes de cada par√°metro\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'{name}.grad', param.grad, epoch + 1)\n",
    "        \n",
    "        ### Fase de validaci√≥n ### \n",
    "        if val_loader is not None:\n",
    "            running_loss_val = 0.0\n",
    "            count_evaluated = 0\n",
    "            count_correct = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch_idx, data_val in enumerate(val_loader, 0):\n",
    "                    inputs_val, labels_val = data_val[0].to(device), data_val[1].to(device)\n",
    "                    outputs_val = model(inputs_val)\n",
    "                    loss = criterion(outputs_val, labels_val)\n",
    "                    running_loss_val += loss.item()\n",
    "                    count_evaluated += inputs_val.shape[0]\n",
    "                    count_correct += torch.sum(labels_val == torch.max(outputs_val, dim=1)[1])\n",
    "                # Presentamos el resumen de la validaci√≥n de la epoch:\n",
    "                val_loss.append(running_loss_val / (val_batch_idx + 1))\n",
    "                \n",
    "                # Apuntamos valor funci√≥n coste \n",
    "                writer.add_scalar('Valor Coste Val', running_loss_val / (val_batch_idx + 1), global_step = epoch + 1)\n",
    "                \n",
    "                acc_val = float(count_correct) / count_evaluated\n",
    "                \n",
    "                # Apuntamos valor funci√≥n coste \n",
    "                writer.add_scalar('Valor Accuracy Val', float(count_correct) / count_evaluated, global_step = epoch + 1)\n",
    "                \n",
    "                print('Validation: epoch %d - acc: %.3f' %\n",
    "                            (epoch + 1, acc_val))\n",
    "                val_acc.append(acc_val)\n",
    "                \n",
    "        \n",
    "        # Apuntamos valor de los par√°metros al finalizar la iteraci√≥n\n",
    "        writer.add_scalar('Running Loss', running_loss, global_step = epoch + 1)\n",
    "        writer.add_scalar('Count Evaluated', count_evaluated, global_step = epoch + 1)\n",
    "        writer.add_scalar('Count Correct', count_correct, global_step = epoch + 1)\n",
    "        \n",
    "    # Devolvemos, tanto el modelo entrenado, como el diccionario con las estad√≠sticas del entrenamiento\n",
    "    return model, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y aqu√≠ definimos la funci√≥n de evaluaci√≥n. \n",
    "\n",
    "**NOTA**: En la pr√°ctica anterior <span style=\"color:red\">hab√≠a un error</span> en la definici√≥n de test(), dado que no se le enviaban el *criterion* a utilizar para calcular el coste de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device='cuda'):\n",
    "    with torch.no_grad():\n",
    "        number_samples = 0\n",
    "        number_correct = 0\n",
    "        running_loss_test = 0.0\n",
    "        for test_batch_idx, data_test in enumerate(test_loader, 0):\n",
    "            inputs_test, labels_test = data_test[0].to(device), data_test[1].long().to(device)\n",
    "            outputs_test = model(inputs_test)\n",
    "            loss = criterion(outputs_test, labels_test)\n",
    "            running_loss_test += loss.cpu().numpy()\n",
    "            # Accuracy:\n",
    "            _, outputs_class = torch.max(outputs_test, dim=1)\n",
    "            number_correct += torch.sum(outputs_class == labels_test).cpu().numpy()\n",
    "            number_samples += len(labels_test)\n",
    "        acc_test = number_correct / number_samples\n",
    "        print('Test - Accuracy: %.3f' % acc_test)\n",
    "        print('Test - CrossEntropy: %.3f' % (running_loss_test / (test_batch_idx+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en la pr√°ctica anterior, debemos fijar los hiperpar√°metros a utilizar para nuestro modelo, y proceder con su entrenamiento y evaluaci√≥n. La parte final de esta pr√°ctica ser√° recrear este proceso.\n",
    "\n",
    "<span style=\"color:green\">**Ejercicio 4**: </span> : Prepara los siguientes puntos:\n",
    "* Modelo LeNetPlus con los siguientes par√°metros:\n",
    "    * Dos capas convolucionales con 64 filtros cada una\n",
    "    * Dos capas lineales ocultas con 384 y 192 neuronas respectivamente\n",
    "* Funci√≥n de coste: Cross Entropy\n",
    "* Optimizador SGD con los siguientes hiperpar√°metros:\n",
    "    * learning_rate = 0.001\n",
    "    * momentum = 0.9\n",
    "    * weight_decay = 0.0001\n",
    "\n",
    "A continuaci√≥n, entrena el modelo y eval√∫alo con el conjunto de test.\n",
    "\n",
    "Por √∫ltimo, analiza la evoluci√≥n del entrenamiento utilizando la herramienta Tensorboard, en base a los valores registrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNetModel(\n",
      "  (conv_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool_1): PoolingLayer()\n",
      "  (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool_2): PoolingLayer()\n",
      "  (lin_1): Linear(in_features=4096, out_features=384, bias=True)\n",
      "  (lin_2): Linear(in_features=384, out_features=192, bias=True)\n",
      "  (salida): Linear(in_features=192, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Creaci√≥n del modelo\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LeNetModel(conv_filters=[64, 64], linear_sizes=[384, 192], num_classes=10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Definici√≥n de funci√≥n de coste y optimizador\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: [1,   704] loss: 2.016\n",
      "Validation: epoch 1 - acc: 0.371\n",
      "Training: [2,   704] loss: 1.657\n",
      "Validation: epoch 2 - acc: 0.425\n",
      "Training: [3,   704] loss: 1.495\n",
      "Validation: epoch 3 - acc: 0.486\n",
      "Training: [4,   704] loss: 1.386\n",
      "Validation: epoch 4 - acc: 0.517\n",
      "Training: [5,   704] loss: 1.308\n",
      "Validation: epoch 5 - acc: 0.543\n",
      "Training: [6,   704] loss: 1.247\n",
      "Validation: epoch 6 - acc: 0.562\n",
      "Training: [7,   704] loss: 1.192\n",
      "Validation: epoch 7 - acc: 0.583\n",
      "Training: [8,   704] loss: 1.144\n",
      "Validation: epoch 8 - acc: 0.595\n",
      "Training: [9,   704] loss: 1.103\n",
      "Validation: epoch 9 - acc: 0.608\n",
      "Training: [10,   704] loss: 1.062\n",
      "Validation: epoch 10 - acc: 0.617\n",
      "Training: [11,   704] loss: 1.019\n",
      "Validation: epoch 11 - acc: 0.627\n",
      "Training: [12,   704] loss: 0.986\n",
      "Validation: epoch 12 - acc: 0.638\n",
      "Training: [13,   704] loss: 0.951\n",
      "Validation: epoch 13 - acc: 0.647\n",
      "Training: [14,   704] loss: 0.925\n",
      "Validation: epoch 14 - acc: 0.661\n",
      "Training: [15,   704] loss: 0.893\n",
      "Validation: epoch 15 - acc: 0.662\n",
      "Training: [16,   704] loss: 0.870\n",
      "Validation: epoch 16 - acc: 0.660\n",
      "Training: [17,   704] loss: 0.844\n",
      "Validation: epoch 17 - acc: 0.676\n",
      "Training: [18,   704] loss: 0.818\n",
      "Validation: epoch 18 - acc: 0.682\n",
      "Training: [19,   704] loss: 0.802\n",
      "Validation: epoch 19 - acc: 0.673\n",
      "Training: [20,   704] loss: 0.779\n",
      "Validation: epoch 20 - acc: 0.687\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable LeNetModel object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, train_stats \u001b[38;5;241m=\u001b[39m train(model, train_loader, criterion, optimizer, val_loader, num_epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable LeNetModel object"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "model = train(model, train_loader, criterion, optimizer, val_loader, num_epochs= 20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar cosas\n",
    "train_loss = train_stats['train_loss']\n",
    "train_acc = train_stats['train_acc']\n",
    "val_loss = train_stats['val_loss']\n",
    "val_acc = train_stats['val_acc']\n",
    "\n",
    "# Error en entrenamiento:\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_loss)), train_loss)\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss')\n",
    "plt.show()\n",
    "# Error en validaci√≥n:\n",
    "plt.figure()\n",
    "plt.plot(range(len(val_loss)), val_loss)\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation loss')\n",
    "plt.show()\n",
    "# Accuracy en entrenamiento y validaci√≥n:\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_acc)), train_acc, 'r--', range(len(val_acc)), val_acc, 'b')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train set', 'Validation set'])\n",
    "plt.title('Model accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test(model, test_loader, criterion = criterion, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50b926a050cc029ac752863e4f86b7e2171f26cfdc0be8c315e356fc3ef03bad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
